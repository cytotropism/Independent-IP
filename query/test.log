2024-12-22T04:37:00.520 INFO  Instance created with id 1491090087
2024-12-22T04:37:00.527 INFO  Starting to check quota of instance 1491090087.
2024-12-22T04:37:00.528 INFO  Instance 1491090087 scheduled by new distributed scheduler
2024-12-22T04:37:00.963 INFO  instance [1491090087] passed quota-limit, start submitting
2024-12-22T04:37:00.965 INFO  Starting to submit instance 1491090087 with memory 3072 MB, without setting cpu core number
2024-12-22T04:37:00.965 INFO  command: [/opt/tiger/dorado-executor/bin/start_executor.sh -Xmx3072m -id 1491090087 -projectId 521]
2024-12-22T04:37:01.083 INFO  http://cronjob-api-va-music.byted.org/v2/job/US-Virginia-Aliyun/music/dp.dorado.executor005/execution/6epsndk4o0006
2024-12-22T04:37:13.126 INFO  Start handling instance action: START_SUBMITTED for instance with id 1491090087
2024-12-22T04:37:13.126 INFO  Start to change instance status from SUBMITTED to EXECUTOR_PENDING.
2024-12-22T04:37:13.894 INFO  Start to download resource []
2024-12-22T04:37:13.904 INFO  Start handling instance action: START_RUNNING for instance with id 1491090087
2024-12-22T04:37:13.904 INFO  Start to change instance status from EXECUTOR_PENDING to RUNNING.
2024-12-22T04:37:13.990 INFO  Refreshing sec token.
2024-12-22T04:37:13.991 INFO  start to generate token with Instance project Id :521, task Id :105520594, primaryAuth type: false, global psm: null, account auth info: ProjectAccountAuthInfo(authType:USER, owner:donglihua, psm:dp.dorado.executor005)
2024-12-22T04:37:14.115 INFO  Reader region: dorado_va
2024-12-22T04:37:14.115 INFO  Writer region: va
2024-12-22T04:37:14.119 INFO  Job cid: 1
Final lark sheet url: https://bytedance.larkoffice.com/sheets/BSd4sE6Cih8sJItdU7Sc8lnYnle
2024-12-22T04:37:20.397 INFO  instance[1491090087] pre-execute finished
2024-12-22T04:37:20.397 INFO  =================================================================
export HADOOP_HOME /opt/tiger/yarn_deploy/hadoop

export HADOOP_CONF_DIR

export HADOOP_CLASSPATH

Use Bytedance Flink

Use new version flink, don't set -yjv

id: yarn: no such user

Don't use Docker. Because the image is not based on dts_runtime_base

Use new version flink

CC_CLASSPATH = /opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-cloud-shuffle-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-connector-preview-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-csv-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-json-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-databus-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-dropwizard-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-opentsdb-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-shaded-zookeeper-3.5.9.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-state-processor-api_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-table_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-table-blink_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-1.2-api-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-api-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-core-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-slf4j-impl-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-dist_2.11-1.11-byted-SNAPSHOT.jar

USER_JAR = /opt/tiger/dts/dts-batch-core.jar

flink_client_classpath_include_user_jar = A
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-slf4j-impl-2.17.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/tiger/yarn_deploy/hadoop-2.6.0-cdh5.4.4/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
DatabusAppender start with : channel ${env:LOG_DATABUS_CHANNEL}, metricsChannel : ${env:LOG_DATABUS_METRICS_CHANNEL}
Dec 22, 2024 4:37:21 AM com.bytedance.data.databus.Cache run
INFO: cache thread run begin
Dec 22, 2024 4:37:21 AM com.bytedance.data.databus.Common load

INFO: load libdomain_socket_emitter.so from META-INF/native/Linux-amd64-64/libdomain_socket_emitter.so, url jar:file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-dist_2.11-1.11-byted-SNAPSHOT.jar!/META-INF/native/Linux-amd64-64/libdomain_socket_emitter.so
Dec 22, 2024 4:37:21 AM com.github.fommil.jni.JniLoader liberalLoad
INFO: successfully loaded /tmp/jniloader6169979179127360654libdomain_socket_emitter.so
Dec 22, 2024 4:37:21 AM com.bytedance.data.databus.Common load
INFO: Load native library META-INF/native/Linux-amd64-64/libdomain_socket_emitter.so successfully
Dec 22, 2024 4:37:21 AM com.bytedance.data.databus.Common <clinit>
INFO: load domain_socket_emitter done
Dec 22, 2024 4:37:21 AM com.bytedance.data.databus.DomainSocketEmitter <clinit>
INFO: Loaded the lib DomainSocket library
2024-12-22 04:37:21,991 INFO  org.apache.flink.client.cli.CliFrontend                      - --------------------------------------------------------------------------------

2024-12-22 04:37:21,998 INFO  org.apache.flink.client.cli.CliFrontend                      -  Starting Command Line Client (Version: 1.11-byted-SNAPSHOT, Scala: 2.11, Rev:0ebcb37, Date:2024-08-01T15:03:19+02:00)
2024-12-22 04:37:21,998 INFO  org.apache.flink.client.cli.CliFrontend                      -  OS current user: root
2024-12-22 04:37:21,998 INFO  org.apache.flink.client.cli.CliFrontend                      -  JVM: Java HotSpot(TM) 64-Bit Server VM - Oracle Corporation - 1.8/25.91-b14
2024-12-22 04:37:21,998 INFO  org.apache.flink.client.cli.CliFrontend                      -  Maximum heap size: 1963 MiBytes
2024-12-22 04:37:21,998 INFO  org.apache.flink.client.cli.CliFrontend                      -  JAVA_HOME: /usr/local/jdk
2024-12-22 04:37:22,020 INFO  org.apache.flink.client.cli.CliFrontend                      -  Hadoop version: 2.6.0-cdh5.4.4-bd346_1.0.0.3318_a5244e3
2024-12-22 04:37:22,020 INFO  org.apache.flink.client.cli.CliFrontend                      -  JVM Options:
2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -Xmx2048M
2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -XX:+HeapDumpOnOutOfMemoryError
2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -XX:HeapDumpPath=./dts_dump

2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -Djava.net.preferIPv6Addresses=true
2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -Dlog.file=/var/log/tiger/flink--client-n190-216-088.log
2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -Dlog4j.configuration=file:/opt/tiger/flink_deploy_conf/log4j-cli.properties
2024-12-22 04:37:22,021 INFO  org.apache.flink.client.cli.CliFrontend                      -     -Dlog4j.configurationFile=file:/opt/tiger/flink_deploy_conf/log4j-cli.properties
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     -Dlogback.configurationFile=file:/opt/tiger/flink_deploy_conf/logback.xml
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -  Program Arguments:
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     run
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     -m
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     yarn-cluster
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yat

2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     Apache Flink Batch
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     -cn
2024-12-22 04:37:22,022 INFO  org.apache.flink.client.cli.CliFrontend                      -     mouse
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yqu
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     root.mouse_ecom_dw
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     -ynm
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     DP_DTS_1491090087_test_larksheet_donglihua
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     -ys
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     8
2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     -ytm

2024-12-22 04:37:22,023 INFO  org.apache.flink.client.cli.CliFrontend                      -     32768
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yjm
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     4096
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     -sae
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     yarn.containers.vcores=8
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     high-availability=none
2024-12-22 04:37:22,024 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     akka.framesize=838860800b

2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     rest.client.max-content-length=838860800
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     rest.server.max-content-length=838860800
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     slot.request.timeout=28800000
2024-12-22 04:37:22,025 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     slotmanager.request-timeout=28800000
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     heartbeat.timeout=180000

2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     akka.watch.heartbeat.pause=181 s
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     akka.ask.timeout=182 s
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,026 INFO  org.apache.flink.client.cli.CliFrontend                      -     akka.client.timeout=183 s
2024-12-22 04:37:22,027 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,027 INFO  org.apache.flink.client.cli.CliFrontend                      -     akka.lookup.timeout=10 min
2024-12-22 04:37:22,027 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,027 INFO  org.apache.flink.client.cli.CliFrontend                      -     web.timeout=600000

2024-12-22 04:37:22,027 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,027 INFO  org.apache.flink.client.cli.CliFrontend                      -     jobmanager.execution.failover-strategy=region
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     jobmanager.execution.attempts-failure-size=6
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     restart-strategy=disable
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     classloader.resolve-order=child-first
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,028 INFO  org.apache.flink.client.cli.CliFrontend                      -     yarn.appmaster.vcores=3

2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     flink-client-classpath-include-user-jar=A
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     taskmanager.memory.task.off-heap.size=4096m
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     jobmanager.memory.off-heap.size=512m
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,029 INFO  org.apache.flink.client.cli.CliFrontend                      -     jobmanager.shutdown-by-client=true
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     execution.shutdown-on-attached-exit=true

2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     taskmanager.memory.managed.fraction=0.2
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     taskmanager.memory.network.max=2g
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     blob.client.socket.timeout=60000
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     blob.fetch.num-concurrent=32
2024-12-22 04:37:22,030 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     resourcemanager.maximum-workers-failure-rate-ratio=2

2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     resourcemanager.maximum-workers-failure-rate=50
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     resourcemanager.workers-failure-interval=28800000
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     taskmanager.network.request-backoff.max=40000
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     task.cancellation.timeout=600000
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,031 INFO  org.apache.flink.client.cli.CliFrontend                      -     taskmanager.network.netty.client.readTimeout.enabled=false

2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     yarn.application-attempts=1
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     yarn.application.priority=1
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     env.java.opts=-Djava.io.tmpdir=./tmp
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     yarn.tags=job=dorado_debugrun_105520594,platform=dorado,grade=3,dorado_priority_code=D5,link=https://dataleap-va.tiktok-row.net/dorado/instance?project=i18n_521&query=105520594&schedule=2024-12-21%2000:00&scheduleEnd=2024-12-21%2000:00,instanceId=1491090087,taskType=larksheet->hive,attempt_id=0,ad_hoc=true,task_frequency=daily,task_trigger_type=debug,is_lookback=0
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     ipv6.enabled=true

2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,032 INFO  org.apache.flink.client.cli.CliFrontend                      -     env.java.opts.taskmanager=-Dcom.rocketmq.remoting.frameMaxLength=134217728
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     containerized.taskmanager.env.SEC_KV_AUTH=1
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     containerized.master.env.SEC_KV_AUTH=1
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     -yD
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     flink.yarn.config.yarn.client.application-metadata-file.save-path=/tmp/appid
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     -j
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     /opt/tiger/dts/dts-batch-core.jar

2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     -xjob_conf
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -     /tmp/dts_conf_DP_DTS_1491090087_test_larksheet_donglihua_1491090087.json
2024-12-22 04:37:22,033 INFO  org.apache.flink.client.cli.CliFrontend                      -  Classpath: /opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-cloud-shuffle-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-connector-preview-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-csv-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-json-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-databus-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-dropwizard-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-opentsdb-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-shaded-zookeeper-3.5.9.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-state-processor-api_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-table_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-table-blink_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-1.2-api-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-api-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-core-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-slf4j-impl-2.17.1.jar:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-dist_2.11-1.11-byted-SNAPSHOT.jar:/opt/tiger/yarn_deploy/hadoop/conf:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/activation-1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/asm-3.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/automaton-1.11-8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/avro-1.7.6-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/btrace-1.0.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/btrace-1.0.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/caffeine-2.6.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-0.0.20.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-collections-3.2.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-el-1.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-io-2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/commons-net-3.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/dnsjava-2.1.7.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/dps-1.3.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/dps-2.0.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/gcs-connector-hadoop2-1.9.5-shaded.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/generex-1.0.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/hadoop-annotations-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/hadoop-auth-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/htrace-core-3.0.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/infsecclient-1.4.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/infsecclient-1.4.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-annotations-2.6.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-core-2.6.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-core-asl-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-databind-2.6.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-dataformat-yaml-2.11.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-datatype-jsr310-2.11.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-module-jaxb-annotations-2.11.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jackson-xc-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jakarta.activation-api-1.2.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jakarta.xml.bind-api-2.3.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/java-jwt-3.11.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/javax.annotation-api-1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jetty-6.1.26.cloudera.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/jwt-1.0.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-client-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-admissionregistration-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-apiextensions-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-apps-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-autoscaling-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-batch-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-certificates-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-common-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-coordination-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-core-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-discovery-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-events-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-extensions-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-flowcontrol-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-metrics-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-networking-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-node-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-policy-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-rbac-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-scheduling-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/kubernetes-model-storageclass-5.10.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/libthrift-0.9.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/common/lib/logging-interceptor-3.12.12.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoo[Log has been truncated-{10111 chars truncated}]/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/jackson-core-asl-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/netty-3.6.10.Final.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/snappy-java-1.1.2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-4mc.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.4.4-tests.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.4.4.jar:/opt/tiger/tez_deploy/conf:/opt/tiger/tez_deploy/tez/:/opt/tiger/tez_deploy/tez/lib/:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/activation-1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/aliyun-sdk-oss-2.4.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/apacheds-i18n-2.0.0-M15.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/api-asn1-api-1.0.0-M20.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/api-util-1.0.0-M20.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/asm-3.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/avro-1.7.6-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/aws-java-sdk-1.7.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-0.0.20.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-beanutils-1.7.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-beanutils-core-1.8.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-cli-1.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-codec-1.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-collections-3.2.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-compress-1.4.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-configuration-1.6.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-digester-1.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-el-1.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-httpclient-3.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-io-2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-lang-2.6.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-logging-1.1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-math3-3.1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/commons-net-3.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/curator-client-2.7.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/curator-framework-2.7.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/curator-recipes-2.7.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/dps-1.2.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/gson-2.2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/guava-11.0.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-aliyun-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-ant-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-archives-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-auth-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-aws-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-azure-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-datajoin-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-distcp-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-extras-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-gridmix-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-openstack-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-rumen-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-sls-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/hamcrest-core-1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/htrace-core-3.0.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/httpclient-4.2.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/httpcore-4.2.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/infsecclient-1.2.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-annotations-2.6.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-core-2.6.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-core-asl-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-databind-2.6.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-jaxrs-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-mapper-asl-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jackson-xc-1.8.8.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jasper-compiler-5.5.23.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jasper-runtime-5.5.23.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/javax.annotation-api-1.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/java-xmlbuilder-0.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jaxb-api-2.2.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jaxb-impl-2.2.3-1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jdom-1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jersey-core-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jersey-json-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jersey-server-1.9.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jets3t-0.9.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jettison-1.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jetty-6.1.26.cloudera.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jetty-util-6.1.26.cloudera.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jsch-0.1.42.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jsp-api-2.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jsr305-3.0.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/junit-4.11.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/jwt-1.0.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/libthrift-0.9.2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/log4j-1.2.17.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/metrics4j-1.0.27.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/metrics-core-3.0.1.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/microsoft-windowsazure-storage-sdk-0.6.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/mockito-all-1.8.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/okhttp-3.8.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/okio-1.13.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/paranamer-2.3.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/protobuf-java-2.5.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/pystream-0.0.1-SNAPSHOT.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/servlet-api-2.5.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/snappy-java-1.1.2.4.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/stax-api-1.0-2.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/xmlenc-0.52.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/xz-1.0.jar:/opt/tiger/yarn_deploy/hadoop/share/hadoop/tools/lib/zookeeper-3.4.5-cdh5.4.4.jar:/opt/tiger/yarn_deploy/hadoop/conf:/opt/tiger/yarn_deploy/hadoop/conf

2024-12-22 04:37:22,034 INFO  org.apache.flink.client.cli.CliFrontend                      - --------------------------------------------------------------------------------
2024-12-22 04:37:22,036 INFO  org.apache.flink.client.cli.CliFrontend                      - clusterName = mouse
2024-12-22 04:37:22,587 INFO  org.apache.flink.client.cli.CliFrontend                      - jobType = JavaFlink
DatabusAppender start with : channel ${env:LOG_DATABUS_CHANNEL}, metricsChannel : ${env:LOG_DATABUS_METRICS_CHANNEL}
2024-12-22 04:37:25,805 INFO  org.apache.hadoop.security.UserGroupInformation              - Initialize ugi, infsecEnabled=true
2024-12-22 04:37:25,897 INFO  org.apache.hadoop.mapreduce.util.ConfigUtil                  - ConfigUtil using default yarn configuration
2024-12-22 04:37:26,304 INFO  org.apache.hadoop.security.UserGroupInformation              - Successfully add SEC_TOKEN token to loginUser

2024-12-22 04:37:26,305 INFO  org.apache.flink.runtime.security.modules.HadoopModule       - Hadoop user set to donglihua (auth:SIMPLE)
2024-12-22 04:37:26,308 INFO  org.apache.flink.runtime.security.modules.JaasModule         - Jaas file will be created as ./tmp/jaas-7061542108872956157.conf.
2024-12-22 04:37:26,314 INFO  org.apache.flink.client.cli.CliFrontend                      - Running 'run' command.
2024-12-22 04:37:26,316 INFO  org.apache.flink.client.cli.CliFrontend                      - owner = 
2024-12-22 04:37:26,422 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - applicationName = DP_DTS_1491090087_test_larksheet_donglihua
2024-12-22 04:37:26,437 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.containers.vcores=8
2024-12-22 04:37:26,438 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: rest.client.max-content-length=838860800
2024-12-22 04:37:26,438 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: env.java.opts.taskmanager=-Dcom.rocketmq.remoting.frameMaxLength=134217728
2024-12-22 04:37:26,438 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.execution.failover-strategy=region
2024-12-22 04:37:26,438 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.memory.task.off-heap.size=4096m

2024-12-22 04:37:26,438 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.lookup.timeout=10 min
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: execution.shutdown-on-attached-exit=true
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: web.timeout=600000
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.tags=job=dorado_debugrun_105520594,platform=dorado,grade=3,dorado_priority_code=D5,link=https://dataleap-va.tiktok-row.net/dorado/instance?project=i18n_521&query=105520594&schedule=2024-12-21%2000:00&scheduleEnd=2024-12-21%2000:00,instanceId=1491090087,taskType=larksheet->hive,attempt_id=0,ad_hoc=true,task_frequency=daily,task_trigger_type=debug,is_lookback=0
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: blob.client.socket.timeout=60000
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: env.java.opts=-Djava.io.tmpdir=./tmp
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: classloader.resolve-order=child-first
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.memory.managed.fraction=0.2
2024-12-22 04:37:26,439 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: containerized.master.env.SEC_KV_AUTH=1
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: slot.request.timeout=28800000

2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: task.cancellation.timeout=600000
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.memory.off-heap.size=512m
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.watch.heartbeat.pause=181 s
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: rest.server.max-content-length=838860800
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: restart-strategy=disable
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: blob.fetch.num-concurrent=32
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: containerized.taskmanager.env.SEC_KV_AUTH=1
2024-12-22 04:37:26,440 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: flink.yarn.config.yarn.client.application-metadata-file.save-path=/tmp/appid
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.appmaster.vcores=3
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: resourcemanager.workers-failure-interval=28800000

2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: slotmanager.request-timeout=28800000
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: flink-client-classpath-include-user-jar=A
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.memory.network.max=2g
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: high-availability=none
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.application.priority=1
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.network.request-backoff.max=40000
2024-12-22 04:37:26,441 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.application-attempts=1
2024-12-22 04:37:26,483 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.shutdown-by-client=true
2024-12-22 04:37:26,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: resourcemanager.maximum-workers-failure-rate=50
2024-12-22 04:37:26,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.framesize=838860800b

2024-12-22 04:37:26,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: heartbeat.timeout=180000
2024-12-22 04:37:26,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.ask.timeout=182 s
2024-12-22 04:37:26,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: ipv6.enabled=true
2024-12-22 04:37:26,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: resourcemanager.maximum-workers-failure-rate-ratio=2
2024-12-22 04:37:26,485 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.network.netty.client.readTimeout.enabled=false
2024-12-22 04:37:26,485 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.client.timeout=183 s
2024-12-22 04:37:26,485 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.execution.attempts-failure-size=6
2024-12-22 04:37:26,511 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to mouse (by conf:yarn.cluster.name)
2024-12-22 04:37:26,511 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Set yarn.cluster.name to mouse
2024-12-22 04:37:26,588 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Set app queue to root.mouse_ecom_dw

2024-12-22 04:37:26,590 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.resourcemanager.connect.max-wait.ms to 900000.
2024-12-22 04:37:26,590 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.resourcemanager.connect.retry-interval.ms to 1000.
2024-12-22 04:37:26,591 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.client.failover-max-attempts to -1.
2024-12-22 04:37:26,594 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to mouse (by queue name: yarn.queue.name=root.mouse_ecom_dw)
2024-12-22 04:37:26,615 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - Won't write application metadata to any file
2024-12-22 04:37:26,616 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - StrictConsistencyEnabled is true, will not use megatron api.
2024-12-22 04:37:26,622 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to mouse (by queue name: yarn.queue.name=root.mouse_ecom_dw)
2024-12-22 04:37:26,947 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dccd:cde2:1001:75b8:88d1:fd5b:af2b:8032 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:37:26,987 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dccd:cde2:1001:75b8:88d1:fd5b:af2b:8032 from donglihua. Request send 0. receive 0. Calls remain 0.
java.net.ConnectException: Connection refused

	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_91]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_91]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:219) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:532) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:496) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:751) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:852) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client$Connection.access$4000(Client.java:487) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1941) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client.call(Client.java:1715) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]

	at org.apache.hadoop.ipc.Client.call(Client.java:1638) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:360) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at com.sun.proxy.$Proxy26.getNewApplication(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getNewApplication(ApplicationClientProtocolPBClientImpl.java:224) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_91]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_91]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_91]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_91]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:328) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:121) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]

	at com.sun.proxy.$Proxy27.getNewApplication(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.client.api.impl.ResLakeClientImpl.getNewApplication(ResLakeClientImpl.java:53) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.yarn.client.api.impl.ResLakeClientImpl.createApplication(ResLakeClientImpl.java:129) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.flink.yarn.cli.FlinkYarnSessionCli.applyCommandLineOptionsToConfiguration(FlinkYarnSessionCli.java:396) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.getEffectiveConfiguration(CliFrontend.java:524) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:300) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:1431) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.lambda$main$12(CliFrontend.java:1594) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_91]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_91]

	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1715) [flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) [flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1594) [flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
2024-12-22 04:37:26,997 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider - Failing over to rm2
2024-12-22 04:37:27,001 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dccd:cde2:1002:acbb:ca51:d404:3090:8032 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:37:27,105 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - new app dc: MALIVA, cluster model01, appid application_1734453112995_4703444
2024-12-22 04:37:27,107 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Change cluster from mouse to model01.
2024-12-22 04:37:27,393 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - applicationName = DP_DTS_1491090087_test_larksheet_donglihua
2024-12-22 04:37:27,395 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.containers.vcores=8
2024-12-22 04:37:27,395 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: rest.client.max-content-length=838860800

2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: env.java.opts.taskmanager=-Dcom.rocketmq.remoting.frameMaxLength=134217728
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.execution.failover-strategy=region
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.memory.task.off-heap.size=4096m
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.lookup.timeout=10 min
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: execution.shutdown-on-attached-exit=true
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: web.timeout=600000
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.tags=job=dorado_debugrun_105520594,platform=dorado,grade=3,dorado_priority_code=D5,link=https://dataleap-va.tiktok-row.net/dorado/instance?project=i18n_521&query=105520594&schedule=2024-12-21%2000:00&scheduleEnd=2024-12-21%2000:00,instanceId=1491090087,taskType=larksheet->hive,attempt_id=0,ad_hoc=true,task_frequency=daily,task_trigger_type=debug,is_lookback=0
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: blob.client.socket.timeout=60000
2024-12-22 04:37:27,396 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: env.java.opts=-Djava.io.tmpdir=./tmp
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: classloader.resolve-order=child-first

2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.memory.managed.fraction=0.2
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: containerized.master.env.SEC_KV_AUTH=1
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: slot.request.timeout=28800000
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: task.cancellation.timeout=600000
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.memory.off-heap.size=512m
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.watch.heartbeat.pause=181 s
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: rest.server.max-content-length=838860800
2024-12-22 04:37:27,397 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: restart-strategy=disable
2024-12-22 04:37:27,398 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: blob.fetch.num-concurrent=32
2024-12-22 04:37:27,398 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: containerized.taskmanager.env.SEC_KV_AUTH=1

2024-12-22 04:37:27,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: flink.yarn.config.yarn.client.application-metadata-file.save-path=/tmp/appid
2024-12-22 04:37:27,484 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.appmaster.vcores=3
2024-12-22 04:37:27,485 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: resourcemanager.workers-failure-interval=28800000
2024-12-22 04:37:27,485 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: slotmanager.request-timeout=28800000
2024-12-22 04:37:27,485 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: flink-client-classpath-include-user-jar=A
2024-12-22 04:37:27,486 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.memory.network.max=2g
2024-12-22 04:37:27,486 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: high-availability=none
2024-12-22 04:37:27,486 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.application.priority=1
2024-12-22 04:37:27,486 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.network.request-backoff.max=40000
2024-12-22 04:37:27,488 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: yarn.application-attempts=1

2024-12-22 04:37:27,488 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.shutdown-by-client=true
2024-12-22 04:37:27,488 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: resourcemanager.maximum-workers-failure-rate=50
2024-12-22 04:37:27,488 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.framesize=838860800b
2024-12-22 04:37:27,488 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: heartbeat.timeout=180000
2024-12-22 04:37:27,489 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.ask.timeout=182 s
2024-12-22 04:37:27,489 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: ipv6.enabled=true
2024-12-22 04:37:27,489 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: resourcemanager.maximum-workers-failure-rate-ratio=2
2024-12-22 04:37:27,489 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: taskmanager.network.netty.client.readTimeout.enabled=false
2024-12-22 04:37:27,489 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: akka.client.timeout=183 s
2024-12-22 04:37:27,489 INFO  org.apache.flink.yarn.cli.FlinkYarnSessionCli                - Dynamic Property set: jobmanager.execution.attempts-failure-size=6

2024-12-22 04:37:27,491 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dccd:cde2:1002:acbb:ca51:d404:3090:8032 from donglihua. Request send 2. receive 2. Calls remain 0.
DatabusAppender start with : channel ${env:LOG_DATABUS_CHANNEL}, metricsChannel : ${env:LOG_DATABUS_METRICS_CHANNEL}
2024-12-22 04:37:27,892 WARN  org.apache.flink.configuration.Configuration                 - Config uses deprecated configuration key 'akka.client.timeout' instead of proper key 'client.timeout'
2024-12-22 04:37:28,004 INFO  org.apache.flink.client.cli.CliFrontend                      - Set the value of queue to root.mouse_ecom_dw.
2024-12-22 04:37:28,083 INFO  org.apache.flink.client.cli.CliFrontend                      - pipeline.jars: [file:/opt/tiger/dts/dts-batch-core.jar]
2024-12-22 04:37:28,084 INFO  org.apache.flink.client.cli.CliFrontend                      - pipeline.external-resources: null
2024-12-22 04:37:28,084 INFO  org.apache.flink.client.cli.CliFrontend                      - Job name is set to: DP_DTS_1491090087_test_larksheet
2024-12-22 04:37:28,085 INFO  org.apache.flink.client.cli.CliFrontend                      - JobUID is not set, set it to jobName for backward-compatibility, jobName: DP_DTS_1491090087_test_larksheet, jobUID: DP_DTS_1491090087_test_larksheet
2024-12-22 04:37:29,914 INFO  org.apache.flink.metrics.opentsdb.OpentsdbReporter           - prefix = flink jobName = DP_DTS_1491090087_test_larksheet whitelistFile = metrics-whitelist.yaml fixedTags = {}
2024-12-22 04:37:30,105 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          - Periodically reporting metrics in intervals of 60 SECONDS for reporter databus_reporter of type org.apache.flink.metrics.databus.DatabusReporter.

2024-12-22 04:37:30,186 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          - Periodically reporting metrics in intervals of 20 SECONDS for reporter opentsdb_reporter of type org.apache.flink.metrics.opentsdb.OpentsdbReporter.
2024-12-22 04:37:30,194 INFO  org.apache.flink.client.cli.CliFrontend                      - Building program from JAR file
2024-12-22 04:37:30,316 INFO  org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders - Create FlinkUserCodeClassLoaders resolveOrder = CHILD_FIRST
2024-12-22 04:37:30,316 INFO  org.apache.flink.runtime.execution.librarycache.FlinkUserCodeClassLoaders - Create FlinkUserCodeClassLoaders urls = [file:/opt/tiger/dts/dts-batch-core.jar]
2024-12-22 04:37:30,391 INFO  org.apache.flink.client.ClientUtils                          - Starting program (detached: false)
2024-12-22 04:37:30,409 INFO  com.bytedance.bitsail.base.version.VersionHolder             - BitSail build version: 0.2.0-SNAPSHOT, build time: 2024-12-05T14:46:27+0800, build commit: 89729d607672e6e7a5681e48b74122244c2f4865
2024-12-22 04:37:30,495 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component default loaded in clazz interface com.bytedance.bitsail.core.api.parser.ConfigurationParser.
2024-12-22 04:37:30,498 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance loaded in clazz interface com.bytedance.bitsail.core.api.parser.ConfigurationParser.
2024-12-22 04:37:30,501 INFO  com.bytedance.bitsail.core.api.parser.ConfigurationHelper    - Config parser: default accepted the arguments.
2024-12-22 04:37:30,586 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Tenant=default load interval: localConfig interval:30s, remoteConfig interval:30s, finally interval:30s

2024-12-22 04:37:30,701 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-flink-interceptor loaded in clazz interface com.bytedance.bitsail.core.api.interceptor.ConfigInterceptor.
2024-12-22 04:37:30,702 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component app-config-interceptor loaded in clazz interface com.bytedance.bitsail.core.api.interceptor.ConfigInterceptor.
2024-12-22 04:37:30,703 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component dump-config-interceptor loaded in clazz interface com.bytedance.bitsail.core.api.interceptor.ConfigInterceptor.
2024-12-22 04:37:30,704 INFO  com.bytedance.bitsail.core.api.interceptor.ConfigInterceptorHelper - Interceptor accepted: bytedance-flink-interceptor for the config.
2024-12-22 04:37:30,715 INFO  com.bytedance.bitsail.core.api.interceptor.ConfigInterceptorHelper - Interceptor accepted: app-config-interceptor for the config.
2024-12-22 04:37:30,716 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.program.interceptor.BytedanceAppConfInterceptor - AppConfig load from batch mode.
2024-12-22 04:37:30,717 INFO  com.bytedance.bitsail.component.client.bytedance.appconfig.AppConfig - Loading config file from path: /opt/tiger/dts/runtime_files/ with loader class com.bytedance.bitsail.component.client.bytedance.appconfig.impl.EnvironLoader
2024-12-22 04:37:30,718 INFO  com.bytedance.bitsail.component.client.bytedance.appconfig.impl.EnvironLoader - Environ loader get environ: va.
2024-12-22 04:37:30,718 INFO  com.bytedance.bitsail.component.client.bytedance.appconfig.impl.EnvironLoader - config file is /opt/tiger/dts/runtime_files/dts_va.conf
2024-12-22 04:37:30,897 INFO  com.bytedance.bitsail.core.Engine                            - BitSail configuration: {

	"job":{
		"common":{
			"job_plugin_lib_dir":"plugin",
			"user_name":"donglihua",
			"flink_queue":"root.mouse_ecom_dw",
			"flink_task_failover_strategy":"region",
			"writer_transport_channel_speed_record":-1,
			"yarn_group":"dorado_521",
			"priority_id":0,
			"project_id":521,

			"writer_transport_channel_speed_byte":-1,
			"checkpoint_enable":false,
			"reader_transport_channel_speed_byte":-1,
			"yarn_tags":"job=dorado_debugrun_105520594,platform=dorado,grade=3,dorado_priority_code=D5,link=https://dataleap-va.tiktok-row.net/dorado/instance?project=i18n_521&query=105520594&schedule=2024-12-21%2000:00&scheduleEnd=2024-12-21%2000:00,instanceId=1491090087,taskType=larksheet->hive,attempt_id=0,ad_hoc=true,task_frequency=daily,task_trigger_type=debug,is_lookback=0",
			"metrics_reporter_type":"bytedance-metric-reporter",
			"writer_transport_channel_flowControl_interval":1000,
			"flink_param_map":" -yD ipv6.enabled=true ",
			"tqs_skip_analysis":"******",
			"yarn_job_name":"DP_DTS_1491090087_test_larksheet_donglihua",
			"messenger_collector_type":"flink",

			"worker_id":"8",
			"reader_transport_channel_flowControl_interval":1000,
			"instance_id":1491090087,
			"flink_client_memory_mb":2048,
			"job_name":"test_larksheet",
			"job_plugin_conf_dir":"plugin_conf",
			"job_id":105520594,
			"reader_transport_channel_speed_record":-1,
			"flink_cluster":"mouse",
			"cid":1,

			"plugin_finder_name":"bytedance-plugin-finder"
		},
		"reader":{
			"columns":[
				{
					"name":"ORDERKEY",
					"type":"string"
				},
				{
					"name":"PARTKEY",

					"type":"string"
				},
				{
					"name":"SUPPKEY",
					"type":"string"
				},
				{
					"name":"LINENUMBER",
					"type":"string"
				},

				{
					"name":"QUANTITY",
					"type":"string"
				},
				{
					"name":"EXTENDEDPRICE",
					"type":"string"
				},
				{
					"name":"DISCOUNT",

					"type":"string"
				},
				{
					"name":"TAX",
					"type":"string"
				},
				{
					"name":"RETURNFLAG",
					"type":"string"
				},

				{
					"name":"LINESTATUS",
					"type":"string"
				},
				{
					"name":"SHIPDATE",
					"type":"string"
				},
				{
					"name":"COMMITDATE",

					"type":"string"
				},
				{
					"name":"RECEIPTDATE",
					"type":"string"
				},
				{
					"name":"SHIPINSTRUCT",
					"type":"string"
				},

				{
					"name":"SHIPMODE",
					"type":"string"
				},
				{
					"name":"COMMENT",
					"type":"string"
				}
			],
			"sheet_url":"https://bytedance.larkoffice.com/sheets/BSd4sE6Cih8sJItdU7Sc8lnYnle",

			"class":"com.bytedance.dts.batch.lark.LarkSheetInputFormat"
		},
		"writer":{
			"partition":"date=20241221",
			"db_name":"ecom_dev",
			"columns":[
				{
					"name":"orderkey",
					"type":"bigint"
				},

				{
					"name":"partkey",
					"type":"bigint"
				},
				{
					"name":"suppkey",
					"type":"bigint"
				},
				{
					"name":"linenumber",

					"type":"bigint"
				},
				{
					"name":"quantity",
					"type":"bigint"
				},
				{
					"name":"extendedprice",
					"type":"decimal(38,6)"
				},

				{
					"name":"discount",
					"type":"decimal(38,6)"
				},
				{
					"name":"tax",
					"type":"decimal(38,6)"
				},
				{
					"name":"returnflag",

					"type":"string"
				},
				{
					"name":"linestatus",
					"type":"string"
				},
				{
					"name":"shipdate",
					"type":"string"
				},

				{
					"name":"commitdate",
					"type":"string"
				},
				{
					"name":"receiptdate",
					"type":"string"
				},
				{
					"name":"shipinstruct",

					"type":"string"
				},
				{
					"name":"shipmode",
					"type":"string"
				},
				{
					"name":"comment",
					"type":"string"
				}

			],
			"table_name":"app_lgt_test_lineitem",
			"class":"com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat",
			"hive_version":"1.2.2",
			"cid":1
		}
	}
}
2024-12-22 04:37:30,899 INFO  com.bytedance.bitsail.base.statistics.VMInfo                 - VMInfo# operatingSystem class => sun.management.OperatingSystemImpl
2024-12-22 04:37:30,900 INFO  com.bytedance.bitsail.core.Engine                            - the machine info  => 


	osInfo:	Oracle Corporation 1.8 25.91-b14
	jvmInfo:	Linux amd64 5.4.210.bsk.5-sign-amd64
	cpu num:	96

	totalPhysicalMemory:	-0.00G
	freePhysicalMemory:	-0.00G
	maxFileDescriptorCount:	-1
	currentOpenFileDescriptorCount:	-1


	GC Names	[PS MarkSweep, PS Scavenge]

	MEMORY_NAME                    | allocation_size                | init_size                      
	PS Eden Space                  | 512.50MB                       | 512.50MB                       
	Code Cache                     | 240.00MB                       | 2.44MB                         
	Compressed Class Space         | 1,024.00MB                     | 0.00MB                         
	PS Survivor Space              | 85.00MB                        | 85.00MB                        
	PS Old Gen                     | 1,365.50MB                     | 1,365.50MB                     
	Metaspace                      | -0.00MB                        | 0.00MB                         



2024-12-22 04:37:30,902 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component localFS loaded in clazz interface com.bytedance.bitsail.base.packages.PluginFinder.
2024-12-22 04:37:30,903 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-plugin-finder loaded in clazz interface com.bytedance.bitsail.base.packages.PluginFinder.
2024-12-22 04:37:30,905 INFO  com.bytedance.bitsail.base.packages.PluginStore              - Try load plugins from base plugin dir /opt/tiger/dts/plugin.
2024-12-22 04:37:30,905 INFO  com.bytedance.bitsail.base.packages.PluginStore              - Try load plugins from base plugin mapping dir /opt/tiger/dts/plugin_conf.
2024-12-22 04:37:31,143 INFO  com.bytedance.bitsail.base.packages.PluginStore              - Try load plugins from base plugin dir /opt/tiger/dts/engines.
2024-12-22 04:37:31,143 INFO  com.bytedance.bitsail.base.packages.PluginStore              - Try load plugins from base plugin mapping dir /opt/tiger/dts/engines/mapping.
2024-12-22 04:37:31,143 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.packages.BytedanceLocalFSPluginFinder - Enabled FlinkUserCodeClassLoader
2024-12-22 04:37:31,151 INFO  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - Plugin Class loader name org.apache.flink.util.ChildFirstClassLoader, urls ["file:/opt/tiger/dts/dts-batch-core.jar"].
2024-12-22 04:37:31,151 WARN  com.bytedance.bitsail.base.packages.PluginStore              - Class bytedance-flink not register in mapping file.

2024-12-22 04:37:31,152 WARN  com.bytedance.bitsail.base.packages.PluginStore              - Class bytedance-flink not register in mapping file.
2024-12-22 04:37:31,155 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-flink loaded in clazz interface com.bytedance.bitsail.core.api.program.Program.
2024-12-22 04:37:31,156 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-sensor-flink loaded in clazz interface com.bytedance.bitsail.core.api.program.Program.
2024-12-22 04:37:31,156 INFO  com.bytedance.bitsail.core.Engine                            - Final program: bytedance-flink.
2024-12-22 04:37:31,207 INFO  org.apache.flink.contrib.streaming.state.RocksDBStateBackend - Currently the localDirs passed by yarn is: null
2024-12-22 04:37:31,207 INFO  org.apache.flink.contrib.streaming.state.RocksDBStateBackend - Using null as rocksdb local directory.
2024-12-22 04:37:31,210 INFO  org.apache.flink.contrib.streaming.state.RocksDBStateBackend - Using predefined options: DEFAULT.
2024-12-22 04:37:31,211 INFO  org.apache.flink.contrib.streaming.state.RocksDBStateBackend - Using default options factory: DefaultConfigurableOptionsFactory{configuredOptions={state.backend.rocksdb.use-fsync=true, state.backend.rocksdb.log.level=INFO_LEVEL, state.backend.rocksdb.stats.dump.period.seconds=600, state.backend.rocksdb.compaction.level.use-dynamic-size=true, state.backend.rocksdb.bloomfilter.enabled=true}}.
2024-12-22 04:37:31,230 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.execution.BaseBytedanceFlinkExecution - Configuring BaseBytedanceFlinkExecution
2024-12-22 04:37:31,283 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.execution.BytedanceFlinkExecution - Configuring BytedanceFlinkExecution

2024-12-22 04:37:31,289 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.program.BytedanceFlinkDAGBuilderFactory - Reader class name is com.bytedance.dts.batch.lark.LarkSheetInputFormat
2024-12-22 04:37:31,289 WARN  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - The class com.bytedance.dts.batch.lark.LarkSheetInputFormat not exists in the class loader, try load from plugin store.
2024-12-22 04:37:31,290 INFO  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - Plugin class loader add plugin url: file:/opt/tiger/dts/plugin/dts-lark-source.jar.
2024-12-22 04:37:31,290 INFO  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - Plugin class loader add plugin url: file:/opt/tiger/dts/plugin/dts-lark-core.jar.
2024-12-22 04:37:31,299 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.program.BytedanceFlinkDAGBuilderFactory - Writer class name is com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat
2024-12-22 04:37:31,300 WARN  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - The class com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat not exists in the class loader, try load from plugin store.
2024-12-22 04:37:31,300 INFO  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - Plugin class loader add plugin url: file:/opt/tiger/dts/plugin/dts-hive1-2-sink.jar.
2024-12-22 04:37:31,301 INFO  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - Plugin class loader add plugin url: file:/opt/tiger/dts/plugin/dts-hadoop2-6-core.jar.
2024-12-22 04:37:31,301 INFO  com.bytedance.bitsail.base.packages.LocalFSPluginFinder      - Plugin class loader add plugin url: file:/opt/tiger/dts/plugin/dts-hive1-2-core.jar.
2024-12-22 04:37:31,410 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Security class com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule is instance of securityContext, loading it.

2024-12-22 04:37:31,410 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - renew security module. and init is true.
2024-12-22 04:37:31,410 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.
2024-12-22 04:37:31,411 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:37:31,411 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.
2024-12-22 04:37:31,413 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Security class com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule is instance of securityContext, loading it.
2024-12-22 04:37:31,413 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - renew security module. and init is true.
2024-12-22 04:37:31,413 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.
2024-12-22 04:37:31,413 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:37:31,413 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.
2024-12-22 04:37:31,487 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component tqs loaded in clazz class com.bytedance.dts.batch.hive.query.service.HiveQueryService.

2024-12-22 04:37:31,488 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component noop loaded in clazz class com.bytedance.dts.batch.hive.query.service.HiveQueryService.
2024-12-22 04:37:31,492 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component jobmanager loaded in clazz class com.bytedance.dts.batch.hive.query.service.HiveQueryService.
2024-12-22 04:37:31,493 INFO  com.bytedance.dts.batch.hive.query.service.HiveQueryServiceFactory - Init hive query service component tqs with class name com.bytedance.dts.batch.hive.query.service.TqsHiveQueryService.
2024-12-22 04:37:31,493 INFO  com.bytedance.dts.batch.hive.query.service.TqsHiveQueryService - key input.tqs.skip_cost_analysis exists.
2024-12-22 04:37:31,493 INFO  com.bytedance.dts.batch.hive.query.service.TqsHiveQueryService - canSkipCostAnalysis is: false
2024-12-22 04:37:31,493 INFO  com.bytedance.dts.batch.hive.query.service.TqsHiveQueryService - Auth token: zti=false, region=null, vdc=null
2024-12-22 04:37:31,494 WARN  com.bytedance.dts.core.execution.interceptor.BytedanceDAGBuilderInterceptor - Skip schema alignment, source engine connector or sink engine connector not supported.
2024-12-22 04:37:31,495 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.
2024-12-22 04:37:31,495 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:37:31,495 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.

2024-12-22 04:37:31,500 INFO  com.bytedance.dts.batch.lark.AbstractLarkConfigure           - lark app id and app secret are not set. this is in internal environment
2024-12-22 04:37:31,506 INFO  com.bytedance.dts.batch.lark.LarkSheetConfig                 - Lark app configs not set in task, will use local configs
2024-12-22 04:37:31,511 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - PRIVATE_LARK_SWITCH is false in TokenHolder.
2024-12-22 04:37:31,512 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - Start to generate or refresh app_access_token...
2024-12-22 04:37:31,512 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - refreshToken using configs: app.id: cli_9f6fe28dd52f500b, open.api.host: https://open.feishu.cn
2024-12-22 04:37:32,586 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - Successfully generate or refresh app_access_token!
2024-12-22 04:37:32,587 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - TokenHolder has been initialized successfully!
2024-12-22 04:37:32,589 INFO  com.bytedance.dts.batch.lark.LarkSheetInputFormat            - PRIVATE_LARK_SWITCH is false in client.
2024-12-22 04:37:33,140 INFO  com.bytedance.dts.batch.lark.LarkSheetUtil                   - Thanks God! lark open api returned successful response
2024-12-22 04:37:33,658 INFO  com.bytedance.dts.batch.lark.LarkSheetUtil                   - Thanks God! lark open api returned successful response

2024-12-22 04:37:33,658 INFO  com.bytedance.dts.batch.lark.LarkSheetUtil                   - sheet header response is: SheetRangeResponse(super=OpenApiBaseResponse(code=0, msg=success), data=SheetRangeResponse.Data(revision=17, spreadsheetToken=BSd4sE6Cih8sJItdU7Sc8lnYnle, valueRange=ValueRange(majorDimension=ROWS, range=cVRCOI!A1:Q1, revision=17, values=[[ORDERKEY, PARTKEY, SUPPKEY, LINENUMBER, QUANTITY, EXTENDEDPRICE, DISCOUNT, TAX, RETURNFLAG, LINESTATUS, SHIPDATE, COMMITDATE, RECEIPTDATE, SHIPINSTRUCT, SHIPMODE, COMMENT, null]])))
2024-12-22 04:37:33,660 INFO  com.bytedance.dts.batch.lark.SheetHeader                     - sheet header generated! sheet header is: [ORDERKEY:0, PARTKEY:1, SUPPKEY:2, LINENUMBER:3, QUANTITY:4, EXTENDEDPRICE:5, DISCOUNT:6, TAX:7, RETURNFLAG:8, LINESTATUS:9, SHIPDATE:10, COMMITDATE:11, RECEIPTDATE:12, SHIPINSTRUCT:13, SHIPMODE:14, COMMENT:15, ], reorder column index is:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
2024-12-22 04:37:33,670 INFO  com.bytedance.dts.batch.lark.LarkSheetInputFormat            - Row type info: Row(ORDERKEY: StringColumn, PARTKEY: StringColumn, SUPPKEY: StringColumn, LINENUMBER: StringColumn, QUANTITY: StringColumn, EXTENDEDPRICE: StringColumn, DISCOUNT: StringColumn, TAX: StringColumn, RETURNFLAG: StringColumn, LINESTATUS: StringColumn, SHIPDATE: StringColumn, COMMITDATE: StringColumn, RECEIPTDATE: StringColumn, SHIPINSTRUCT: StringColumn, SHIPMODE: StringColumn, COMMENT: StringColumn)
2024-12-22 04:37:33,670 INFO  com.bytedance.dts.batch.lark.LarkSheetInputFormat            - paramMap info: {dateTimeRenderOption=FormattedString}
2024-12-22 04:37:33,670 INFO  com.bytedance.dts.core.legacy.connector.InputFormatPlugin    - Init Input Flow Control: 
2024-12-22 04:37:33,671 INFO  com.bytedance.bitsail.base.ratelimit.Channel                 - Records Speed Per Second: -1
2024-12-22 04:37:33,671 INFO  com.bytedance.bitsail.base.ratelimit.Channel                 - Bytes Speed Per Second: -1
2024-12-22 04:37:33,672 INFO  com.bytedance.bitsail.base.messenger.checker.LowVolumeTestChecker - Low Volume test is disabled, threshold: -1
2024-12-22 04:37:33,672 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - PRIVATE_LARK_SWITCH is false in TokenHolder.
2024-12-22 04:37:33,672 INFO  com.bytedance.dts.batch.lark.TokenHolder                     - TokenHolder has been initialized successfully!

2024-12-22 04:37:33,674 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component flink loaded in clazz interface com.bytedance.bitsail.base.messenger.MessengerBuilder.
2024-12-22 04:37:33,675 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component no_operation loaded in clazz interface com.bytedance.bitsail.base.messenger.MessengerBuilder.
2024-12-22 04:37:33,677 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component flink loaded in clazz interface com.bytedance.bitsail.base.dirty.DirtyCollectorBuilder.
2024-12-22 04:37:33,677 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component noop loaded in clazz interface com.bytedance.bitsail.base.dirty.DirtyCollectorBuilder.
2024-12-22 04:37:33,678 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component accumulator loaded in clazz interface com.bytedance.bitsail.base.dirty.DirtyCollectorBuilder.
2024-12-22 04:37:33,685 INFO  com.bytedance.dts.common.util.ConfigUtils                    - Init filesystem by hadoopConf: {}
2024-12-22 04:37:35,745 INFO  com.bytedance.bitsail.shaded.hive.shim.HiveShimLoader        - Load hive shim, version: 1.2.0
2024-12-22 04:37:35,750 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Initializing cache: eviction-timeout=300 initial-capacity=0 maximum-capacity=100
2024-12-22 04:37:35,872 INFO  com.bytedance.metrics.udpclient.MetricsClient                - metrics sdk use localhost inet socket to emit metrics
2024-12-22 04:37:35,874 INFO  org.apache.hadoop.hive.metastore.tools.ClientMetricsHandler  - properties:{version=1.2.2-bd165, groupId=org.apache.hive, artifactId=hive-metastore}

2024-12-22 04:37:35,874 INFO  org.apache.hadoop.hive.metastore.tools.ClientMetricsHandler  - class:org.apache.hadoop.hive.metastore.HiveMetaStoreClient, version:1.2.2-bd165
2024-12-22 04:37:35,874 INFO  org.apache.hadoop.hive.metastore.tools.ClientMetricsHandler  - Local host: 10.190.216.88
2024-12-22 04:37:43,607 INFO  org.apache.hadoop.hive.metastore.trace.thrift.TTraceMap      - The current env support MDC? true
2024-12-22 04:37:43,608 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:37:43,610 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:43,610 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:43,747 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:43,748 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:43,748 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:43,771 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613

2024-12-22 04:37:43,772 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:43,787 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:12:287::153]:9587
2024-12-22 04:37:43,822 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:12:287::153]:9587
2024-12-22 04:37:44,646 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:44,646 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:44,651 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:44,651 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:44,651 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:44,658 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:44,658 INFO  hive.metastore                                               - Parsed nodes size: 613

2024-12-22 04:37:44,663 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:37:44,842 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,842 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,844 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,846 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,848 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,851 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,853 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,853 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,856 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@

2024-12-22 04:37:44,857 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:44,878 INFO  com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase    - GHFS version: hadoop2-1.9.5
2024-12-22 04:37:44,884 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,212 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,212 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,216 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,223 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,234 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,241 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,284 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@

2024-12-22 04:37:45,285 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:45,302 INFO  org.apache.hadoop.hdfs.iomonitor.IOMonitor                   - IOMonitor disabled
2024-12-22 04:37:45,303 INFO  org.apache.hadoop.hdfs.ioscheduler.IOScheduler               - IOScheduler disabled
2024-12-22 04:37:45,346 INFO  org.apache.flink.shaded.hadoop2.com.bytedance.btrace.ByteTrace - --- BYTETRACE ---
user_agent: "TCE"
user: "donglihua"
application_tags {
  application_id_type: PSM
  application_id: "dp.dorado.executor005"
}

application_tags {
  application_id_type: PSM
  application_id: "dp.dorado.executor005"
}

2024-12-22 04:37:45,374 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider -  Log in ConfiguredFailoverProxyProvider Initialized proxy lists: 
 host: harunavaali
 consul enabled: false
 Consul service name:
 Consul Dcs: 

 ProxyThresholdNums:5
 AlertNumsDecreaseRate:0.8
 refreshIntervalMS:300000
2024-12-22 04:37:45,386 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider - conf addressesOfNns: 
[/fdbd:dc61:10:201:0:0:0:19:65212, /fdbd:dc61:10:201:0:0:0:39:65212, /fdbd:dc61:10:201:0:0:0:21:65212, /fdbd:dc61:10:219:0:0:0:166:65212, /fdbd:dc61:10:219:0:0:0:164:65212, /fdbd:dc61:9:179:0:0:0:170:65212, /fdbd:dc61:9:53:0:0:0:45:65212, /fdbd:dc61:9:459:0:0:0:146:65212, /fdbd:dc61:9:453:0:0:0:29:65212, /fdbd:dc61:9:467:0:0:0:159:65212, /fdbd:dc61:6:131:0:0:0:12:65212, /fdbd:dc61:9:563:0:0:0:165:65212, /fdbd:dc61:6:135:0:0:0:14:65212, /fdbd:dc61:6:135:0:0:0:12:65212, /fdbd:dc61:6:135:0:0:0:44:65212, /fdbd:dc61:6:135:0:0:0:19:65212, /fdbd:dc61:6:135:0:0:0:48:65212, /fdbd:dc61:6:135:0:0:0:47:65212, /fdbd:dc61:6:136:0:0:0:90:65212, /fdbd:dc61:6:136:0:0:0:87:65212, /fdbd:dc61:6:136:0:0:0:91:65212, /fdbd:dc61:6:136:0:0:0:93:65212, /fdbd:dc61:6:136:0:0:0:92:65212, /fdbd:dc61:6:137:0:0:0:133:65212, /fdbd:dc61:6:137:0:0:0:132:65212, /fdbd:dc61:6:137:0:0:0:135:65212, /fdbd:dc61:6:137:0:0:0:134:65212, /fdbd:dc61:6:138:0:0:0:196:65212, /fdbd:dc61:6:138:0:0:0:194:65212, /fdbd:dc61:6:138:0:0:0:197:65212, /fdbd:dc61:6:138:0:0:0:201:65212, /fdbd:dc61:6:138:0:0:0:199:65212, /fdbd:dc61:6:139:0:0:0:13:65212, /fdbd:dc61:6:139:0:0:0:12:65212, /fdbd:dc61:6:139:0:0:0:18:65212, /fdbd:dc61:6:139:0:0:0:14:65212, /fdbd:dc61:6:140:0:0:0:69:65212, /fdbd:dc61:6:140:0:0:0:67:65212, /fdbd:dc61:6:140:0:0:0:73:65212, /fdbd:dc61:6:140:0:0:0:70:65212, /fdbd:dc61:c:235:0:0:0:139:65212, /fdbd:dc61:a:185:0:0:0:47:65212, /fdbd:dc61:c:235:0:0:0:142:65212, /fdbd:dc61:a:237:0:0:0:31:65212, /fdbd:dc61:a:237:0:0:0:30:65212, /fdbd:dc61:7:266:0:0:0:92:65212, /fdbd:dc61:7:266:0:0:0:85:65212, /fdbd:dc61:4:35:0:0:0:14:65212, /fdbd:dc61:7:272:0:0:0:225:65212, /fdbd:dc61:7:272:0:0:0:208:65212, /fdbd:dc61:4:37:0:0:0:168:65212, /fdbd:dc61:7:292:0:0:0:209:65212, /fdbd:dc61:4:37:0:0:0:153:65212, /fdbd:dc61:7:278:0:0:0:66:65212, /fdbd:dc61:7:292:0:0:0:207:65212, /fdbd:dc61:4:40:0:0:0:88:65212, /fdbd:dc61:7:290:0:0:0:105:65212, /fdbd:dc61:4:39:0:0:0:12:65212, /fdbd:dc61:7:290:0:0:0:85:65212, /fdbd:dc61:101:168:0:0:0:92:65212, /fdbd:dc61:7:294:0:0:0:84:65212, /fdbd:dc61:4:41:0:0:0:139:65212, /fdbd:dc61:7:294:0:0:0:82:65212, /fdbd:dc61:101:214:0:0:0:221:65212, /fdbd:dc61:7:292:0:0:0:224:65212, /fdbd:dc61:101:214:0:0:0:218:65212, /fdbd:dc61:7:292:0:0:0:213:65212, /fdbd:dc61:101:214:0:0:0:203:65212, /fdbd:dc61:101:214:0:0:0:198:65212, /fdbd:dc61:101:168:0:0:0:76:65212, /fdbd:dc61:101:214:0:0:0:207:65212, /fdbd:dc61:7:282:0:0:0:91:65212, /fdbd:dc61:101:214:0:0:0:215:65212, /fdbd:dc61:7:280:0:0:0:237:65212, /fdbd:dc61:101:168:0:0:0:83:65212, /fdbd:dc61:7:280:0:0:0:224:65212, /fdbd:dc61:101:168:0:0:0:75:65212, /fdbd:dc61:101:109:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:217:65212, /fdbd:dc61:101:129:0:0:0:168:65212, /fdbd:dc61:7:288:0:0:0:213:65212, /fdbd:dc61:5:22:0:0:0:196:65212, /fdbd:dc61:7:288:0:0:0:212:65212, /fdbd:dc61:101:134:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:208:65212, /fdbd:dc61:7:290:0:0:0:75:65212, /fdbd:dc61:7:290:0:0:0:73:65212, /fdbd:dc61:7:288:0:0:0:232:65212, /fdbd:dc61:101:216:0:0:0:92:65212, /fdbd:dc61:4:33:0:0:0:130:65212, /fdbd:dc61:4:34:0:0:0:210:65212, /fdbd:dc61:4:36:0:0:0:100:65212, /fdbd:dc61:6:406:0:0:0:223:65212, /fdbd:dc61:6:300:0:0:0:19:65212, /fdbd:dc61:6:303:0:0:0:219:65212, /fdbd:dc61:6:303:0:0:0:199:65212, /fdbd:dc61:6:300:0:0:0:21:65212, /fdbd:dc61:b:487:0:0:0:134:65212, /fdbd:dc61:6:408:0:0:0:95:65212, /fdbd:dc61:a:14:0:0:0:107:65212, /fdbd:dc61:c:423:0:0:0:153:65212, /fdbd:dc61:a:15:0:0:0:132:65212, /fdbd:dc61:a:318:0:0:0:91:65212, /fdbd:dc61:a:16:0:0:0:197:65212, /fdbd:dc61:10:195:0:0:0:143:65212, /fdbd:dc61:a:468:0:0:0:235:65212, /fdbd:dc61:10:197:0:0:0:14:65212, /fdbd:dc61:10:195:0:0:0:155:65212, /fdbd:dc61:10:199:0:0:0:138:65212, /fdbd:dc61:10:197:0:0:0:53:65212, /fdbd:dc61:10:201:0:0:0:17:65212, /fdbd:dc61:10:199:0:0:0:156:65212]
conf addressesOfNns nums:112
2024-12-22 04:37:45,629 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using switch reads; ; threshold=30ms; window length=16; change block reader ratio=0.5; read in same dc weight=4; increase read size min speed up=5; default block reader minimum read bytes=1MB; maximum read bytes=100MB; minimum read bytes=2MB
2024-12-22 04:37:45,641 INFO  org.apache.hadoop.hdfs.DFSClient                             - initialize client metrics with metricTag normal applicationId:dp.dorado.executor005 ...
2024-12-22 04:37:45,641 INFO  org.apache.hadoop.fs.FileSystem                              - Initialize DistributedFileSystem. Yarn Deploy version: @@version@@
2024-12-22 04:37:45,649 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dc61:c:423:0:0:0:153:65212 from donglihua, trySasl=true, tryCustomSasl=false

2024-12-22 04:37:45,685 INFO  org.apache.hadoop.security.token.btdsec.SecTokenSelector     - Looking for a token with service fdbd:dc61:c:423:0:0:0:153:65212
2024-12-22 04:37:46,268 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:46,268 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:46,289 INFO  org.apache.hadoop.hive.ql.session.SessionState               - Created local directory: /tmp/833f51e5-9a6d-410e-b429-80965bbd5cff_resources
2024-12-22 04:37:46,494 INFO  org.apache.hadoop.hive.ql.session.SessionState               - Created HDFS directory: /tmp/hive_i18n/SCRATCH_DATE/hive-root/donglihua/833f51e5-9a6d-410e-b429-80965bbd5cff
2024-12-22 04:37:46,682 INFO  org.apache.hadoop.hive.ql.session.SessionState               - Created local directory: /tmp/root/833f51e5-9a6d-410e-b429-80965bbd5cff
2024-12-22 04:37:46,872 INFO  org.apache.hadoop.hive.ql.session.SessionState               - Created HDFS directory: /tmp/hive_i18n/SCRATCH_DATE/hive-root/donglihua/833f51e5-9a6d-410e-b429-80965bbd5cff/_tmp_space.db
2024-12-22 04:37:47,062 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:37:47,062 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:47,062 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice

2024-12-22 04:37:47,064 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:47,065 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:47,065 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:47,071 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:47,071 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:47,073 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:6:303::215]:9487
2024-12-22 04:37:47,074 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:6:303::215]:9487
2024-12-22 04:37:47,826 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:47,826 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:47,828 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88

2024-12-22 04:37:47,828 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:47,828 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:47,834 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:47,834 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:47,837 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:37:47,871 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842267_9OvuLx0ZsZ
2024-12-22 04:37:47,905 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842267_9OvuLx0ZsZ, Latency=34ms
2024-12-22 04:37:47,906 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842267_11EaHhuQWy
2024-12-22 04:37:47,989 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842267_11EaHhuQWy, Latency=83ms
2024-12-22 04:37:48,000 INFO  com.bytedance.bitsail.shaded.hive.client.HiveMetaClientUtil  - fetch database: ecom_dev table: app_lgt_test_lineitem location: hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem, Taken: 12 sec.

2024-12-22 04:37:48,001 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842268_YsFL0mYxlS
2024-12-22 04:37:48,002 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - The hive output location path is /default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem
2024-12-22 04:37:48,003 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - The job tmp output path path is /default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002
2024-12-22 04:37:48,003 INFO  org.apache.flink.runtime.fs.hdfs.HadoopFsFactory             - Initialize hadoop filesystem(uri=hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002)
2024-12-22 04:37:48,039 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:37:48,039 INFO  org.apache.flink.runtime.fs.hdfs.HadoopFsFactory             - Initialize filesystem hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002
2024-12-22 04:37:48,040 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider -  Log in ConfiguredFailoverProxyProvider Initialized proxy lists: 
 host: harunava
 consul enabled: false
 Consul service name:

 Consul Dcs: 
 ProxyThresholdNums:5
 AlertNumsDecreaseRate:0.8
 refreshIntervalMS:300000
2024-12-22 04:37:48,047 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider - conf addressesOfNns: 
[/fdbd:dc61:10:201:0:0:0:19:65212, /fdbd:dc61:10:201:0:0:0:39:65212, /fdbd:dc61:10:201:0:0:0:21:65212, /fdbd:dc61:10:219:0:0:0:166:65212, /fdbd:dc61:10:219:0:0:0:164:65212, /fdbd:dc61:9:179:0:0:0:170:65212, /fdbd:dc61:9:53:0:0:0:45:65212, /fdbd:dc61:9:459:0:0:0:146:65212, /fdbd:dc61:9:453:0:0:0:29:65212, /fdbd:dc61:9:467:0:0:0:159:65212, /fdbd:dc61:6:131:0:0:0:12:65212, /fdbd:dc61:9:563:0:0:0:165:65212, /fdbd:dc61:6:135:0:0:0:14:65212, /fdbd:dc61:6:135:0:0:0:12:65212, /fdbd:dc61:6:135:0:0:0:44:65212, /fdbd:dc61:6:135:0:0:0:19:65212, /fdbd:dc61:6:135:0:0:0:48:65212, /fdbd:dc61:6:135:0:0:0:47:65212, /fdbd:dc61:6:136:0:0:0:90:65212, /fdbd:dc61:6:136:0:0:0:87:65212, /fdbd:dc61:6:136:0:0:0:91:65212, /fdbd:dc61:6:136:0:0:0:93:65212, /fdbd:dc61:6:136:0:0:0:92:65212, /fdbd:dc61:6:137:0:0:0:133:65212, /fdbd:dc61:6:137:0:0:0:132:65212, /fdbd:dc61:6:137:0:0:0:135:65212, /fdbd:dc61:6:137:0:0:0:134:65212, /fdbd:dc61:6:138:0:0:0:196:65212, /fdbd:dc61:6:138:0:0:0:194:65212, /fdbd:dc61:6:138:0:0:0:197:65212, /fdbd:dc61:6:138:0:0:0:201:65212, /fdbd:dc61:6:138:0:0:0:199:65212, /fdbd:dc61:6:139:0:0:0:13:65212, /fdbd:dc61:6:139:0:0:0:12:65212, /fdbd:dc61:6:139:0:0:0:18:65212, /fdbd:dc61:6:139:0:0:0:14:65212, /fdbd:dc61:6:140:0:0:0:69:65212, /fdbd:dc61:6:140:0:0:0:67:65212, /fdbd:dc61:6:140:0:0:0:73:65212, /fdbd:dc61:6:140:0:0:0:70:65212, /fdbd:dc61:c:235:0:0:0:139:65212, /fdbd:dc61:a:185:0:0:0:47:65212, /fdbd:dc61:c:235:0:0:0:142:65212, /fdbd:dc61:a:237:0:0:0:31:65212, /fdbd:dc61:a:237:0:0:0:30:65212, /fdbd:dc61:7:266:0:0:0:92:65212, /fdbd:dc61:7:266:0:0:0:85:65212, /fdbd:dc61:4:35:0:0:0:14:65212, /fdbd:dc61:7:272:0:0:0:225:65212, /fdbd:dc61:7:272:0:0:0:208:65212, /fdbd:dc61:4:37:0:0:0:168:65212, /fdbd:dc61:7:292:0:0:0:209:65212, /fdbd:dc61:4:37:0:0:0:153:65212, /fdbd:dc61:7:278:0:0:0:66:65212, /fdbd:dc61:7:292:0:0:0:207:65212, /fdbd:dc61:4:40:0:0:0:88:65212, /fdbd:dc61:7:290:0:0:0:105:65212, /fdbd:dc61:4:39:0:0:0:12:65212, /fdbd:dc61:7:290:0:0:0:85:65212, /fdbd:dc61:101:168:0:0:0:92:65212, /fdbd:dc61:7:294:0:0:0:84:65212, /fdbd:dc61:4:41:0:0:0:139:65212, /fdbd:dc61:7:294:0:0:0:82:65212, /fdbd:dc61:101:214:0:0:0:221:65212, /fdbd:dc61:7:292:0:0:0:224:65212, /fdbd:dc61:101:214:0:0:0:218:65212, /fdbd:dc61:7:292:0:0:0:213:65212, /fdbd:dc61:101:214:0:0:0:203:65212, /fdbd:dc61:101:214:0:0:0:198:65212, /fdbd:dc61:101:168:0:0:0:76:65212, /fdbd:dc61:101:214:0:0:0:207:65212, /fdbd:dc61:7:282:0:0:0:91:65212, /fdbd:dc61:101:214:0:0:0:215:65212, /fdbd:dc61:7:280:0:0:0:237:65212, /fdbd:dc61:101:168:0:0:0:83:65212, /fdbd:dc61:7:280:0:0:0:224:65212, /fdbd:dc61:101:168:0:0:0:75:65212, /fdbd:dc61:101:109:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:217:65212, /fdbd:dc61:101:129:0:0:0:168:65212, /fdbd:dc61:7:288:0:0:0:213:65212, /fdbd:dc61:5:22:0:0:0:196:65212, /fdbd:dc61:7:288:0:0:0:212:65212, /fdbd:dc61:101:134:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:208:65212, /fdbd:dc61:7:290:0:0:0:75:65212, /fdbd:dc61:7:290:0:0:0:73:65212, /fdbd:dc61:7:288:0:0:0:232:65212, /fdbd:dc61:101:216:0:0:0:92:65212, /fdbd:dc61:4:33:0:0:0:130:65212, /fdbd:dc61:4:34:0:0:0:210:65212, /fdbd:dc61:4:36:0:0:0:100:65212, /fdbd:dc61:6:406:0:0:0:223:65212, /fdbd:dc61:6:300:0:0:0:19:65212, /fdbd:dc61:6:303:0:0:0:219:65212, /fdbd:dc61:6:303:0:0:0:199:65212, /fdbd:dc61:6:300:0:0:0:21:65212, /fdbd:dc61:b:487:0:0:0:134:65212, /fdbd:dc61:6:408:0:0:0:95:65212, /fdbd:dc61:a:14:0:0:0:107:65212, /fdbd:dc61:c:423:0:0:0:153:65212, /fdbd:dc61:a:15:0:0:0:132:65212, /fdbd:dc61:a:318:0:0:0:91:65212, /fdbd:dc61:a:16:0:0:0:197:65212, /fdbd:dc61:10:195:0:0:0:143:65212, /fdbd:dc61:a:468:0:0:0:235:65212, /fdbd:dc61:10:197:0:0:0:14:65212, /fdbd:dc61:10:195:0:0:0:155:65212, /fdbd:dc61:10:199:0:0:0:138:65212, /fdbd:dc61:10:197:0:0:0:53:65212, /fdbd:dc61:10:201:0:0:0:17:65212, /fdbd:dc61:10:199:0:0:0:156:65212]
conf addressesOfNns nums:112
2024-12-22 04:37:48,048 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using switch reads; ; threshold=30ms; window length=16; change block reader ratio=0.5; read in same dc weight=4; increase read size min speed up=5; default block reader minimum read bytes=1MB; maximum read bytes=100MB; minimum read bytes=2MB
2024-12-22 04:37:48,048 INFO  org.apache.hadoop.fs.FileSystem                              - Initialize DistributedFileSystem. Yarn Deploy version: @@version@@
2024-12-22 04:37:48,051 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dc61:7:292:0:0:0:209:65212 from donglihua, trySasl=true, tryCustomSasl=false

2024-12-22 04:37:48,053 INFO  org.apache.hadoop.security.token.btdsec.SecTokenSelector     - Looking for a token with service fdbd:dc61:7:292:0:0:0:209:65212
2024-12-22 04:37:48,063 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - tmp output path hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 not exist.
2024-12-22 04:37:48,065 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 58 users=2 expired=false closed=false
2024-12-22 04:37:48,065 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842268_ZIUx5DR1YI
2024-12-22 04:37:48,065 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:37:48,066 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2
2024-12-22 04:37:48,066 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:37:48,066 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:37:49,406 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:37:49,406 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice

2024-12-22 04:37:49,406 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:49,408 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:49,408 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:49,408 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:49,417 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:49,418 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:49,420 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:7:231::143]:9818
2024-12-22 04:37:49,420 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:7:231::143]:9818
2024-12-22 04:37:50,799 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:50,799 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice

2024-12-22 04:37:50,801 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:50,802 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:50,802 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:50,807 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:50,807 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:50,810 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:37:50,815 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_fields, CS_TRACE_ID=CS_1734842270_vNHYzmQN07
2024-12-22 04:37:50,893 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842270_vNHYzmQN07, Latency=78ms
2024-12-22 04:37:50,894 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842270_qKDLHSD0pU
2024-12-22 04:37:50,895 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 58 users=2 expired=false closed=false

2024-12-22 04:37:50,896 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842270_KyLhuKdDT4
2024-12-22 04:37:50,896 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:37:50,896 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2
2024-12-22 04:37:50,897 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:37:50,897 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:37:52,236 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:37:52,236 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:52,236 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:52,238 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:52,238 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88

2024-12-22 04:37:52,238 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:52,244 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:52,244 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:52,247 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:7:133::43]:11711
2024-12-22 04:37:52,247 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:7:133::43]:11711
2024-12-22 04:37:52,837 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:52,837 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:52,840 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:52,840 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:52,841 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true

2024-12-22 04:37:52,847 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:52,847 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:52,850 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:37:52,851 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842272_JuLLgWnOBg
2024-12-22 04:37:52,921 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842272_JuLLgWnOBg, Latency=71ms
2024-12-22 04:37:52,921 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842272_fzd6WUtIih
2024-12-22 04:37:52,922 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 58 users=2 expired=false closed=false
2024-12-22 04:37:52,922 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842272_ornG82N8x1
2024-12-22 04:37:52,923 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:37:52,923 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2

2024-12-22 04:37:52,923 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:37:52,923 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:37:54,529 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:37:54,529 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:54,530 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:54,532 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:54,532 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:54,532 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:54,540 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:54,541 INFO  hive.metastore                                               - Parsed nodes size: 613

2024-12-22 04:37:54,543 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:14:457::14]:10826
2024-12-22 04:37:54,545 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:14:457::14]:10826
2024-12-22 04:37:55,975 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:55,976 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:55,978 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:55,978 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:55,979 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:55,985 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:55,985 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:55,987 INFO  hive.metastore                                               - Connected to metastore.

2024-12-22 04:37:55,988 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842275_4wfncnUFU3
2024-12-22 04:37:56,063 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842275_4wfncnUFU3, Latency=75ms
2024-12-22 04:37:56,064 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842276_TyZ0d8UCDn
2024-12-22 04:37:56,065 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 58 users=2 expired=false closed=false
2024-12-22 04:37:56,065 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842276_rjVnV7dDoA
2024-12-22 04:37:56,066 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:37:56,066 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2
2024-12-22 04:37:56,066 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:37:56,066 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:37:57,423 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372

2024-12-22 04:37:57,423 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:57,423 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:57,425 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:57,425 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:57,425 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:57,431 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:57,432 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:57,434 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:7:431::137]:11354
2024-12-22 04:37:57,434 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:7:431::137]:11354
2024-12-22 04:37:58,058 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dc61:7:292:0:0:0:209:65212 from donglihua. Request send 1. receive 1. Calls remain 0.

2024-12-22 04:37:58,199 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:58,199 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:58,201 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:58,201 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:58,201 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:58,206 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:58,206 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:37:58,207 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:37:58,208 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842278_IEySySN9El
2024-12-22 04:37:58,277 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842278_IEySySN9El, Latency=69ms

2024-12-22 04:37:58,277 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842278_F5YLXvsjgM
2024-12-22 04:37:58,278 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - Fetch from hive metastore, hive schema: {orderkey,partkey,suppkey,linenumber,quantity,extendedprice,discount,tax,returnflag,linestatus,shipdate,commitdate,receiptdate,shipinstruct,shipmode,comment,bigint:bigint:bigint:bigint:bigint:decimal(38,6):decimal(38,6):decimal(38,6):string:string:string:string:string:string:string:string}, 
hive format: StorageDescriptor(cols:[FieldSchema(name:orderkey, type:bigint, comment:orderkey), FieldSchema(name:partkey, type:bigint, comment:partkey), FieldSchema(name:suppkey, type:bigint, comment:suppkey), FieldSchema(name:linenumber, type:bigint, comment:linenumber), FieldSchema(name:quantity, type:bigint, comment:quantity), FieldSchema(name:extendedprice, type:decimal(38,6), comment:extendedprice), FieldSchema(name:discount, type:decimal(38,6), comment:discount), FieldSchema(name:tax, type:decimal(38,6), comment:tax), FieldSchema(name:returnflag, type:string, comment:returnflag), FieldSchema(name:linestatus, type:string, comment:linestatus), FieldSchema(name:shipdate, type:string, comment:shipdate), FieldSchema(name:commitdate, type:string, comment:commitdate), FieldSchema(name:receiptdate, type:string, comment:receiptdate), FieldSchema(name:shipinstruct, type:string, comment:shipinstruct), FieldSchema(name:shipmode, type:string, comment:shipmode), FieldSchema(name:comment, type:string, comment:comment)], location:hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), 
hive serde parameter: {serialization.format=1}, 
hive table parameter: {is_core=false, creation_platform=coral, spark.sql.sources.schema.partCol.0=date, transient_lastDdlTime=1734842126, parquet.compression=zstd, ttl=7, spark.sql.create.version=3.2.1-bd1-SNAPSHOT, last_update_time=1734842126, is_starred=false, spark.sql.sources.schema.numPartCols=1, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"orderkey","type":"long","nullable":true,"metadata":{"comment":"orderkey"}},{"name":"partkey","type":"long","nullable":true,"metadata":{"comment":"partkey"}},{"name":"suppkey","type":"long","nullable":true,"metadata":{"comment":"suppkey"}},{"name":"linenumber","type":"long","nullable":true,"metadata":{"comment":"linenumber"}},{"name":"quantity","type":"long","nullable":true,"metadata":{"comment":"quantity"}},{"name":"extendedprice","type":"decimal(38,6)","nullable":true,"metadata":{"comment":"extendedprice"}},{"name":"discount","type":"decimal(38,6)","nullable":true,"metadata":{"comment":"discount"}},{"name":"tax","type":"decimal(38,6)","nullable":true,"metadata":{"comment":"tax"}},{"name":"returnflag","type":"string","nullable":true,"metadata":{"comment":"returnflag"}},{"name":"linestatus","type":"string","nullable":true,"metadata":{"comment":"linestatus"}},{"name":"shipdate","type":"string","nullable":true,"metadata":{"comment":"shipdate"}},{"name":"commitdate","type":"string","nullable":true,"metadata":{"comment":"commitdate"}},{"name":"receiptdate","type":"string","nullable":true,"metadata":{"comment":"receiptdate"}},{"name":"shipinstruct","type":"string","nullable":true,"metadata":{"comment":"shipinstruct"}},{"name":"shipmode","type":"string","nullable":true,"metadata":{"comment":"shipmode"}},{"name":"comment","type":"string","nullable":true,"metadata":{"comment":"comment"}},{"name":"date","type":"string","nullable":true,"metadata":{"comment":"date"}}]}, ttl_extension={"type":"pname"}, spark.sql.sources.schema.numParts=1, status=3}, 
column mapping: {SUPPKEY=2, SHIPMODE=14, PARTKEY=1, QUANTITY=4, COMMITDATE=11, ORDERKEY=0, TAX=7, COMMENT=15, DISCOUNT=6, SHIPDATE=10, SHIPINSTRUCT=13, EXTENDEDPRICE=5, RECEIPTDATE=12, RETURNFLAG=8, LINENUMBER=3, LINESTATUS=9}
2024-12-22 04:37:58,280 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 58 users=2 expired=false closed=false
2024-12-22 04:37:58,280 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842278_Wc4EBH9sDt
2024-12-22 04:37:58,280 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:37:58,280 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2

2024-12-22 04:37:58,280 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:37:58,280 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:37:59,552 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:37:59,552 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:37:59,552 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:37:59,554 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:37:59,554 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:37:59,555 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:37:59,564 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:37:59,565 INFO  hive.metastore                                               - Parsed nodes size: 613

2024-12-22 04:37:59,567 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:7:112::230]:11447
2024-12-22 04:37:59,568 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:7:112::230]:11447
2024-12-22 04:38:00,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842280002, timeStamp 1734842280
2024-12-22 04:38:00,261 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:38:00,261 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:38:00,263 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:38:00,263 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:38:00,263 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:38:00,268 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:38:00,269 INFO  hive.metastore                                               - Parsed nodes size: 613

2024-12-22 04:38:00,271 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:38:00,271 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_fields, CS_TRACE_ID=CS_1734842280_vzsyJwGNRw
2024-12-22 04:38:00,434 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842280_vzsyJwGNRw, Latency=163ms
2024-12-22 04:38:00,435 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842280_lE0Rrd9PqP
2024-12-22 04:38:00,438 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - get column info from metastore {"returnflag":"string","linenumber":"bigint","quantity":"bigint","orderkey":"bigint","shipmode":"string","discount":"decimal(38,6)","tax":"decimal(38,6)","suppkey":"bigint","partkey":"bigint","shipinstruct":"string","linestatus":"string","extendedprice":"decimal(38,6)","comment":"string","receiptdate":"string","commitdate":"string","shipdate":"string"}
2024-12-22 04:38:00,438 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - base columnInfos: [ColumnInfo(name=orderkey, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=partkey, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=suppkey, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=linenumber, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=quantity, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=extendedprice, type=decimal(38,6), expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=discount, type=decimal(38,6), expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=tax, type=decimal(38,6), expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=returnflag, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=linestatus, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=shipdate, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=commitdate, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=receiptdate, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=shipinstruct, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=shipmode, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=comment, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1)]
2024-12-22 04:38:00,439 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - table schema map columnInfos: [ColumnInfo(name=orderkey, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=partkey, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=suppkey, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=linenumber, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=quantity, type=bigint, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=extendedprice, type=decimal(38,6), expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=discount, type=decimal(38,6), expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=tax, type=decimal(38,6), expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=returnflag, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=linestatus, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=shipdate, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=commitdate, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=receiptdate, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=shipinstruct, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=shipmode, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1), ColumnInfo(name=comment, type=string, expr=null, functionType=null, comment=null, scale=-1, precision=-1)]
2024-12-22 04:38:00,591 INFO  com.bytedance.dts.batch.hive.partition.HiveColumnsAndPartitions - partition info: [HivePartitionInfo(name=date, index=0, order=0, type=null, objectInspector=null, objectConversion=null, value=20241221, defaultValue=null, dateFormat=null, isDynamic=false)]
2024-12-22 04:38:00,592 INFO  com.bytedance.dts.core.legacy.connector.OutputFormatPlugin   - Auth type is : gdpr
2024-12-22 04:38:00,593 INFO  com.bytedance.dts.core.legacy.connector.OutputFormatPlugin   - Init Output Flow Control: 

2024-12-22 04:38:00,593 INFO  com.bytedance.bitsail.base.ratelimit.Channel                 - Records Speed Per Second: -1
2024-12-22 04:38:00,593 INFO  com.bytedance.bitsail.base.ratelimit.Channel                 - Bytes Speed Per Second: -1
2024-12-22 04:38:00,594 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component flink loaded in clazz interface com.bytedance.bitsail.base.messenger.MessengerBuilder.
2024-12-22 04:38:00,595 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component no_operation loaded in clazz interface com.bytedance.bitsail.base.messenger.MessengerBuilder.
2024-12-22 04:38:00,596 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component flink loaded in clazz interface com.bytedance.bitsail.base.dirty.DirtyCollectorBuilder.
2024-12-22 04:38:00,596 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component noop loaded in clazz interface com.bytedance.bitsail.base.dirty.DirtyCollectorBuilder.
2024-12-22 04:38:00,596 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component accumulator loaded in clazz interface com.bytedance.bitsail.base.dirty.DirtyCollectorBuilder.
2024-12-22 04:38:00,601 INFO  com.bytedance.dts.core.reader.PluginableInputFormatDAGBuilder - Reader parallelism advice taken 0(s).
2024-12-22 04:38:00,602 INFO  com.bytedance.dts.core.writer.PluginableOutputFormatDAGBuilder - Writer parallelism advice: 1.
2024-12-22 04:38:00,602 INFO  com.bytedance.bitsail.flink.core.parallelism.FlinkParallelismAdvisor - reader parallelisms:

2024-12-22 04:38:00,602 INFO  com.bytedance.bitsail.flink.core.parallelism.FlinkParallelismAdvisor - reader LarkSheet has parallelism: 1
2024-12-22 04:38:00,602 INFO  com.bytedance.bitsail.flink.core.parallelism.FlinkParallelismAdvisor - writer parallelisms:
2024-12-22 04:38:00,603 INFO  com.bytedance.bitsail.flink.core.parallelism.FlinkParallelismAdvisor - writer Hive has parallelism: 1
2024-12-22 04:38:00,603 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.
2024-12-22 04:38:00,603 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:38:00,603 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:38:00,603 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:38:00,604 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.
2024-12-22 04:38:00,604 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:38:00,604 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.

2024-12-22 04:38:00,604 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:38:00,604 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:38:00,604 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:38:00,604 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.
2024-12-22 04:38:00,605 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:38:00,686 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component client-metric-plugin loaded in clazz interface com.bytedance.bitsail.base.runtime.RuntimePluggable.
2024-12-22 04:38:00,686 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component progress-plugin loaded in clazz interface com.bytedance.bitsail.base.runtime.RuntimePluggable.
2024-12-22 04:38:00,688 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-job-progress-plugin loaded in clazz interface com.bytedance.bitsail.base.runtime.RuntimePluggable.
2024-12-22 04:38:00,693 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component log loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:38:00,694 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component nop loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.

2024-12-22 04:38:00,694 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-metric-reporter loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:38:00,694 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component influxdb loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:38:00,696 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Metric prefix is dp.dts.
2024-12-22 04:38:00,700 INFO  com.bytedance.metrics.udpclient.MetricsClient                - metrics sdk use localhost inet socket to emit metrics
2024-12-22 04:38:00,703 INFO  com.bytedance.bitsail.base.version.ReleaseTagHolder          - Release tag is 
2024-12-22 04:38:00,706 INFO  com.bytedance.bitsail.base.metrics.manager.BitSailMetricManager - MetricManager responsible for group 'client' of task UNKNOWN with identifier '0' is initialized by c.b.b.b.r.m.BitSailClientMetricsPlugin#configure:81
2024-12-22 04:38:00,707 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.releaseTagHeartbeat{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:38:00,708 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.start{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:38:00,708 INFO  com.bytedance.bitsail.core.bytedance.flink.bridge.plugins.BytedanceJobProgressPlugin - Flink batch job deploy mode: yarn.
2024-12-22 04:38:00,710 INFO  com.bytedance.bitsail.component.progress.bytedance.context.BytedanceYarnJobDeployContext - yarn cluster: mouse, yarn job name: null

2024-12-22 04:38:00,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:38:00,712 INFO  com.bytedance.bitsail.flink.core.runtime.restart.FixedDelayRestartStrategyBuilder - Region failover is configured, and fixed delay restart strategy will configure. Restart attempts number is 2
2024-12-22 04:38:00,715 INFO  com.bytedance.bitsail.core.api.program.UnifiedProgram        - Final global configuration: {
	"job":{
		"common":{
			"job_plugin_lib_dir":"plugin",
			"user_name":"donglihua",
			"flink_queue":"root.mouse_ecom_dw",
			"flink_task_failover_strategy":"region",
			"writer_transport_channel_speed_record":-1,

			"yarn_group":"dorado_521",
			"priority_id":0,
			"project_id":521,
			"writer_transport_channel_speed_byte":-1,
			"checkpoint_enable":false,
			"reader_transport_channel_speed_byte":-1,
			"yarn_tags":"job=dorado_debugrun_105520594,platform=dorado,grade=3,dorado_priority_code=D5,link=https://dataleap-va.tiktok-row.net/dorado/instance?project=i18n_521&query=105520594&schedule=2024-12-21%2000:00&scheduleEnd=2024-12-21%2000:00,instanceId=1491090087,taskType=larksheet->hive,attempt_id=0,ad_hoc=true,task_frequency=daily,task_trigger_type=debug,is_lookback=0",
			"metrics_reporter_type":"bytedance-metric-reporter",
			"writer_transport_channel_flowControl_interval":1000,
			"internal_instance_id":"1491090087_1734842251156",

			"flink_param_map":" -yD ipv6.enabled=true ",
			"tqs_skip_analysis":"******",
			"yarn_job_name":"DP_DTS_1491090087_test_larksheet_donglihua",
			"messenger_collector_type":"flink",
			"worker_id":"8",
			"reader_transport_channel_flowControl_interval":1000,
			"instance_id":1491090087,
			"flink_client_memory_mb":2048,
			"job_name":"test_larksheet",
			"job_plugin_conf_dir":"plugin_conf",

			"job_id":105520594,
			"reader_transport_channel_speed_record":-1,
			"flink_cluster":"mouse",
			"cid":1,
			"plugin_finder_name":"bytedance-plugin-finder"
		},
		"reader":{
			"columns":[
				{
					"name":"ORDERKEY",

					"type":"string"
				},
				{
					"name":"PARTKEY",
					"type":"string"
				},
				{
					"name":"SUPPKEY",
					"type":"string"
				},

				{
					"name":"LINENUMBER",
					"type":"string"
				},
				{
					"name":"QUANTITY",
					"type":"string"
				},
				{
					"name":"EXTENDEDPRICE",

					"type":"string"
				},
				{
					"name":"DISCOUNT",
					"type":"string"
				},
				{
					"name":"TAX",
					"type":"string"
				},

				{
					"name":"RETURNFLAG",
					"type":"string"
				},
				{
					"name":"LINESTATUS",
					"type":"string"
				},
				{
					"name":"SHIPDATE",

					"type":"string"
				},
				{
					"name":"COMMITDATE",
					"type":"string"
				},
				{
					"name":"RECEIPTDATE",
					"type":"string"
				},

				{
					"name":"SHIPINSTRUCT",
					"type":"string"
				},
				{
					"name":"SHIPMODE",
					"type":"string"
				},
				{
					"name":"COMMENT",

					"type":"string"
				}
			],
			"sheet_url":"https://bytedance.larkoffice.com/sheets/BSd4sE6Cih8sJItdU7Sc8lnYnle",
			"class":"com.bytedance.dts.batch.lark.LarkSheetInputFormat"
		},
		"writer":{
			"partition":"date=20241221",
			"db_name":"ecom_dev",
			"columns":[

				{
					"name":"orderkey",
					"type":"bigint"
				},
				{
					"name":"partkey",
					"type":"bigint"
				},
				{
					"name":"suppkey",

					"type":"bigint"
				},
				{
					"name":"linenumber",
					"type":"bigint"
				},
				{
					"name":"quantity",
					"type":"bigint"
				},

				{
					"name":"extendedprice",
					"type":"decimal(38,6)"
				},
				{
					"name":"discount",
					"type":"decimal(38,6)"
				},
				{
					"name":"tax",

					"type":"decimal(38,6)"
				},
				{
					"name":"returnflag",
					"type":"string"
				},
				{
					"name":"linestatus",
					"type":"string"
				},

				{
					"name":"shipdate",
					"type":"string"
				},
				{
					"name":"commitdate",
					"type":"string"
				},
				{
					"name":"receiptdate",

					"type":"string"
				},
				{
					"name":"shipinstruct",
					"type":"string"
				},
				{
					"name":"shipmode",
					"type":"string"
				},

				{
					"name":"comment",
					"type":"string"
				}
			],
			"table_name":"app_lgt_test_lineitem",
			"class":"com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat",
			"hive_version":"1.2.2",
			"cid":1
		}

	}
}
2024-12-22 04:38:00,844 INFO  com.bytedance.bitsail.flink.core.execution.FlinkExecutionEnviron - Setting classpath ["file:/opt/tiger/dts/dts-batch-core.jar","file:/opt/tiger/dts/plugin/dts-hive1-2-core.jar","file:/opt/tiger/dts/plugin/dts-lark-source.jar","file:/opt/tiger/dts/dts-batch-core.jar","file:/opt/tiger/dts/plugin/dts-hive1-2-sink.jar","file:/opt/tiger/dts/plugin/dts-lark-core.jar","file:/opt/tiger/dts/plugin/dts-hadoop2-6-core.jar"]
2024-12-22 04:38:00,856 INFO  org.apache.flink.api.java.ExecutionEnvironment               - The new/update configuration size of main method is 1, new configuration details is: {}, update configuration details is: {pipeline.jars=("file:/opt/tiger/dts/dts-batch-core.jar","file:/opt/tiger/dts/dts-batch-core.jar;file:/opt/tiger/dts/plugin/dts-hive1-2-core.jar;file:/opt/tiger/dts/plugin/dts-lark-source.jar;file:/opt/tiger/dts/dts-batch-core.jar;file:/opt/tiger/dts/plugin/dts-hive1-2-sink.jar;file:/opt/tiger/dts/plugin/dts-lark-core.jar;file:/opt/tiger/dts/plugin/dts-hadoop2-6-core.jar")}.
2024-12-22 04:38:00,943 INFO  org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator - Checkpoint is disabled.
2024-12-22 04:38:00,953 INFO  org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator - Checkpoint is disabled.
2024-12-22 04:38:00,961 INFO  org.apache.flink.streaming.api.graph.StreamingJobGraphGenerator - Checkpoint is disabled.
2024-12-22 04:38:00,963 INFO  org.apache.flink.client.deployment.executors.PipelineExecutorUtils - JobGraph is generated with JobUID = DP_DTS_1491090087_test_larksheet, JobID = 256215842b1a6fd6ead19ba389539de0, ResourceGroup = null
2024-12-22 04:38:00,967 INFO  org.apache.flink.client.cli.CheckpointVerifier               - CLIENT_CHECKPOINT_VERIFICATION_ENABLE is set false, skip checkpoint verification
2024-12-22 04:38:00,968 WARN  org.apache.flink.yarn.configuration.YarnLogConfigUtil        - The configuration directory ('/opt/tiger/flink_deploy_conf') already contains a LOG4J config file.If you want to use logback, then please delete or rename the log configuration file.

2024-12-22 04:38:00,997 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to model01 (by conf:yarn.cluster.name)
2024-12-22 04:38:00,997 INFO  org.apache.flink.yarn.YarnClusterClientFactory               - Set yarn.cluster.name to model01
2024-12-22 04:38:01,014 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.client.application-metadata-file.save-path to /tmp/appid.
2024-12-22 04:38:01,015 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.resourcemanager.connect.retry-interval.ms to 1000.
2024-12-22 04:38:01,015 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.resourcemanager.connect.max-wait.ms to 900000.
2024-12-22 04:38:01,015 INFO  org.apache.flink.yarn.Utils                                  - update yarn config set yarn.client.failover-max-attempts to -1.
2024-12-22 04:38:01,015 INFO  org.apache.flink.yarn.YarnClusterClientFactory               - Use ResLake init yarn client.
2024-12-22 04:38:01,016 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to mouse (by queue name: yarn.queue.name=root.mouse_ecom_dw)
2024-12-22 04:38:01,016 WARN  org.apache.hadoop.yarn.conf.YarnConfiguration                - User configuration for cluster name is conflict. (mouse in yarn.queue.name != model01 in yarn.cluster.name). Using default cluster name in queue.
2024-12-22 04:38:01,033 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - Would write application metadata to /tmp/appid

2024-12-22 04:38:01,033 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - StrictConsistencyEnabled is true, will not use megatron api.
2024-12-22 04:38:01,034 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to mouse (by queue name: yarn.queue.name=root.mouse_ecom_dw)
2024-12-22 04:38:01,034 WARN  org.apache.hadoop.yarn.conf.YarnConfiguration                - User configuration for cluster name is conflict. (mouse in yarn.queue.name != model01 in yarn.cluster.name). Using default cluster name in queue.
2024-12-22 04:38:01,058 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - No path for the flink jar passed. Using the location of class org.apache.flink.yarn.YarnClusterDescriptor to locate the jar
2024-12-22 04:38:01,091 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils - The derived from fraction jvm overhead memory (3.200gb (3435973888 bytes)) is greater than its max value 1024.000mb (1073741824 bytes), max value will be used instead
2024-12-22 04:38:01,092 INFO  org.apache.flink.runtime.util.config.memory.ProcessMemoryUtils - The derived from fraction network memory (9.225gb (9905268720 bytes)) is greater than its max value 2.000gb (2147483648 bytes), max value will be used instead
2024-12-22 04:38:01,096 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - app Timestamp is 1734453112995
2024-12-22 04:38:01,096 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - app id is 4703444
2024-12-22 04:38:01,098 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dccd:cde2:1001:75b8:88d1:fd5b:af2b:8032 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:38:01,099 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dccd:cde2:1001:75b8:88d1:fd5b:af2b:8032 from donglihua. Request send 0. receive 0. Calls remain 0.

java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) ~[?:1.8.0_91]
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) ~[?:1.8.0_91]
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:219) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:532) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:496) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:751) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:852) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client$Connection.access$4000(Client.java:487) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1941) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]

	at org.apache.hadoop.ipc.Client.call(Client.java:1715) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.Client.call(Client.java:1638) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:360) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at com.sun.proxy.$Proxy26.getNewApplication(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.api.impl.pb.client.ApplicationClientProtocolPBClientImpl.getNewApplication(ApplicationClientProtocolPBClientImpl.java:224) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_91]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_91]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_91]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_91]
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:328) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]

	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:121) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at com.sun.proxy.$Proxy27.getNewApplication(Unknown Source) ~[?:?]
	at org.apache.hadoop.yarn.client.api.impl.ResLakeClientImpl.getNewApplication(ResLakeClientImpl.java:53) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.hadoop.yarn.client.api.impl.ResLakeClientImpl.createApplication(ResLakeClientImpl.java:129) ~[flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]
	at org.apache.flink.yarn.YarnClusterDescriptor.deployInternal(YarnClusterDescriptor.java:521) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.yarn.YarnClusterDescriptor.deployJobCluster(YarnClusterDescriptor.java:427) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor.execute(AbstractJobClusterExecutor.java:111) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.executeAsync(StreamExecutionEnvironment.java:1913) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.program.StreamContextEnvironment.executeAsync(StreamContextEnvironment.java:203) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.program.StreamContextEnvironment.execute(StreamContextEnvironment.java:94) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]

	at org.apache.flink.streaming.api.environment.StreamExecutionEnvironment.execute(StreamExecutionEnvironment.java:1779) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at com.bytedance.bitsail.flink.core.execution.FlinkExecutionEnviron.run(FlinkExecutionEnviron.java:199) ~[dts-batch-core.jar:?]
	at com.bytedance.bitsail.core.api.program.UnifiedProgram.submit(UnifiedProgram.java:119) ~[dts-batch-core.jar:?]
	at com.bytedance.bitsail.core.Engine.run(Engine.java:100) ~[dts-batch-core.jar:?]
	at com.bytedance.bitsail.core.Engine.start(Engine.java:69) ~[dts-batch-core.jar:?]
	at com.bytedance.bitsail.core.Engine.main(Engine.java:60) ~[dts-batch-core.jar:?]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_91]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_91]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_91]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_91]

	at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:358) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:216) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:170) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.executeProgram(CliFrontend.java:1135) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.run(CliFrontend.java:342) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.parseParameters(CliFrontend.java:1431) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.lambda$main$12(CliFrontend.java:1594) ~[flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_91]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_91]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1715) [flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:2.6.0-cdh5.4.4-bd346-11.0-byted-SNAPSHOT]

	at org.apache.flink.runtime.security.contexts.HadoopSecurityContext.runSecured(HadoopSecurityContext.java:41) [flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
	at org.apache.flink.client.cli.CliFrontend.main(CliFrontend.java:1594) [flink-dist_2.11-1.11-byted-SNAPSHOT.jar:1.11-byted-SNAPSHOT]
2024-12-22 04:38:01,102 INFO  org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider - Failing over to rm2
2024-12-22 04:38:01,103 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dccd:cde2:1002:acbb:ca51:d404:3090:8032 from donglihua, trySasl=true, tryCustomSasl=false
DatabusAppender start with : channel ${env:LOG_DATABUS_CHANNEL}, metricsChannel : ${env:LOG_DATABUS_METRICS_CHANNEL}
2024-12-22 04:38:01,199 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - Home directory: hdfs://harunavaali/flink_maliva/model01/1.11.
2024-12-22 04:38:01,211 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - flinkExternalJarDependencies = null
2024-12-22 04:38:01,217 INFO  org.apache.flink.yarn.YarnApplicationFileUploader            - The <localPath, relativePath> map from the directory(/opt/tiger/flink_deploy/deploy/flink-1.11/lib) is {file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-cloud-shuffle-1.11-byted-SNAPSHOT.jar=lib/flink-cloud-shuffle-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-connector-preview-1.11-byted-SNAPSHOT.jar=lib/flink-connector-preview-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-csv-1.11-byted-SNAPSHOT.jar=lib/flink-csv-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-dist_2.11-1.11-byted-SNAPSHOT.jar=lib/flink-dist_2.11-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-json-1.11-byted-SNAPSHOT.jar=lib/flink-json-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-databus-1.11-byted-SNAPSHOT.jar=lib/flink-metrics-databus-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-dropwizard-1.11-byted-SNAPSHOT.jar=lib/flink-metrics-dropwizard-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-metrics-opentsdb-1.11-byted-SNAPSHOT.jar=lib/flink-metrics-opentsdb-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar=lib/flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-shaded-zookeeper-3.5.9.jar=lib/flink-shaded-zookeeper-3.5.9.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-state-processor-api_2.11-1.11-byted-SNAPSHOT.jar=lib/flink-state-processor-api_2.11-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-table-blink_2.11-1.11-byted-SNAPSHOT.jar=lib/flink-table-blink_2.11-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/flink-table_2.11-1.11-byted-SNAPSHOT.jar=lib/flink-table_2.11-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-1.2-api-2.17.1.jar=lib/log4j-1.2-api-2.17.1.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-api-2.17.1.jar=lib/log4j-api-2.17.1.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-core-2.17.1.jar=lib/log4j-core-2.17.1.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/lib/log4j-slf4j-impl-2.17.1.jar=lib/log4j-slf4j-impl-2.17.1.jar}.
2024-12-22 04:38:01,254 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:01,254 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled

2024-12-22 04:38:01,322 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/log4j.properties fileId:373282242180 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472660590_368494684017
2024-12-22 04:38:03,259 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:03,259 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:03,335 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-cloud-shuffle-1.11-byted-SNAPSHOT.jar fileId:373282257557 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472676099_368494699529
2024-12-22 04:38:03,708 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Closing client with non-zero user count: users=1 expired=true
2024-12-22 04:38:03,709 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842283_hN0d0kLnQO
2024-12-22 04:38:03,709 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Closing client with non-zero user count: users=1 expired=true
2024-12-22 04:38:03,709 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842283_hjIWHJTDAR
2024-12-22 04:38:03,709 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Closing client with non-zero user count: users=1 expired=true
2024-12-22 04:38:03,709 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842283_oQLha7wXuv

2024-12-22 04:38:03,709 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Closing client with non-zero user count: users=1 expired=true
2024-12-22 04:38:03,710 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842283_5R6xyl42Wd
2024-12-22 04:38:03,929 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:03,929 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:03,938 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-connector-preview-1.11-byted-SNAPSHOT.jar fileId:373282262634 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472681223_368494704654
2024-12-22 04:38:10,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:38:11,107 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dccd:cde2:1002:acbb:ca51:d404:3090:8032 from donglihua. Request send 2. receive 2. Calls remain 0.
2024-12-22 04:38:13,930 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dc61:c:423:0:0:0:153:65212 from donglihua. Request send 62. receive 62. Calls remain 0.
2024-12-22 04:38:20,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:38:23,716 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dc61:c:423:0:0:0:153:65212 from donglihua, trySasl=true, tryCustomSasl=false

2024-12-22 04:38:23,717 INFO  org.apache.hadoop.security.token.btdsec.SecTokenSelector     - Looking for a token with service fdbd:dc61:c:423:0:0:0:153:65212
2024-12-22 04:38:23,741 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:23,741 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:23,748 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-csv-1.11-byted-SNAPSHOT.jar fileId:373282344419 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472762740_368494786219
2024-12-22 04:38:23,894 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:23,894 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:23,901 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-json-1.11-byted-SNAPSHOT.jar fileId:373282344988 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472763313_368494786792
2024-12-22 04:38:24,069 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:24,069 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:24,076 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-metrics-databus-1.11-byted-SNAPSHOT.jar fileId:373282345510 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472763835_368494787314

2024-12-22 04:38:24,516 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:24,516 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:24,523 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-metrics-dropwizard-1.11-byted-SNAPSHOT.jar fileId:373282346993 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472765312_368494788791
2024-12-22 04:38:24,637 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:24,637 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:24,645 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-metrics-opentsdb-1.11-byted-SNAPSHOT.jar fileId:373282347409 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472765728_368494789207
2024-12-22 04:38:24,916 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:24,917 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:24,926 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar fileId:373282348106 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472766465_368494789944
2024-12-22 04:38:28,733 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false

2024-12-22 04:38:28,733 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:28,742 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-shaded-zookeeper-3.5.9.jar fileId:373282360072 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472778548_368494802034
2024-12-22 04:38:28,916 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:28,916 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:28,923 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-state-processor-api_2.11-1.11-byted-SNAPSHOT.jar fileId:373282360836 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472779343_368494802829
2024-12-22 04:38:29,127 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:29,127 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:29,136 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-table-blink_2.11-1.11-byted-SNAPSHOT.jar fileId:373282362025 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472780531_368494804017
2024-12-22 04:38:29,772 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:29,772 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled

2024-12-22 04:38:29,779 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/flink-table_2.11-1.11-byted-SNAPSHOT.jar fileId:373282364994 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472783563_368494807051
2024-12-22 04:38:30,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842310002, timeStamp 1734842310
2024-12-22 04:38:30,159 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:30,159 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:30,167 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/log4j-1.2-api-2.17.1.jar fileId:373282366148 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472784741_368494808229
2024-12-22 04:38:30,334 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:30,334 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:30,356 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/log4j-api-2.17.1.jar fileId:373282367220 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472785756_368494809244
2024-12-22 04:38:30,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:38:40,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds

2024-12-22 04:38:41,268 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dc61:c:423:0:0:0:153:65212 from donglihua. Request send 73. receive 73. Calls remain 0.
2024-12-22 04:38:50,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:38:56,804 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dc61:c:423:0:0:0:153:65212 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:38:56,805 INFO  org.apache.hadoop.security.token.btdsec.SecTokenSelector     - Looking for a token with service fdbd:dc61:c:423:0:0:0:153:65212
2024-12-22 04:38:56,829 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:38:56,830 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:38:56,839 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/log4j-core-2.17.1.jar fileId:373282518985 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472937983_368494961515
2024-12-22 04:39:00,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842340002, timeStamp 1734842340
2024-12-22 04:39:00,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:39:01,068 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false

2024-12-22 04:39:01,068 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:01,079 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/lib/log4j-slf4j-impl-2.17.1.jar fileId:373282538509 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472957510_368494981052
2024-12-22 04:39:01,275 INFO  org.apache.flink.yarn.YarnApplicationFileUploader            - The <localPath, relativePath> map from the directory(/opt/tiger/flink_deploy/deploy/flink-1.11/plugins) is {file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/README.txt=plugins/README.txt, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/external-resource-gpu/flink-external-resource-gpu-1.11-byted-SNAPSHOT.jar=plugins/external-resource-gpu/flink-external-resource-gpu-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/external-resource-gpu/gpu-discovery-common.sh=plugins/external-resource-gpu/gpu-discovery-common.sh, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/external-resource-gpu/nvidia-gpu-discovery.sh=plugins/external-resource-gpu/nvidia-gpu-discovery.sh, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/hive-udf/flink-hive-udf.jar=plugins/hive-udf/flink-hive-udf.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-datadog/flink-metrics-datadog-1.11-byted-SNAPSHOT.jar=plugins/metrics-datadog/flink-metrics-datadog-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-graphite/flink-metrics-graphite-1.11-byted-SNAPSHOT.jar=plugins/metrics-graphite/flink-metrics-graphite-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-influx/flink-metrics-influxdb-1.11-byted-SNAPSHOT.jar=plugins/metrics-influx/flink-metrics-influxdb-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-jmx/flink-metrics-jmx-1.11-byted-SNAPSHOT.jar=plugins/metrics-jmx/flink-metrics-jmx-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-prometheus/flink-metrics-prometheus-1.11-byted-SNAPSHOT.jar=plugins/metrics-prometheus/flink-metrics-prometheus-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-slf4j/flink-metrics-slf4j-1.11-byted-SNAPSHOT.jar=plugins/metrics-slf4j/flink-metrics-slf4j-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/metrics-statsd/flink-metrics-statsd-1.11-byted-SNAPSHOT.jar=plugins/metrics-statsd/flink-metrics-statsd-1.11-byted-SNAPSHOT.jar, file:/opt/tiger/flink_deploy/deploy/flink-1.11/plugins/s3-fs-presto/flink-s3-fs-presto-1.11-byted-SNAPSHOT.jar=plugins/s3-fs-presto/flink-s3-fs-presto-1.11-byted-SNAPSHOT.jar}.
2024-12-22 04:39:01,284 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:01,285 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:01,292 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/README.txt fileId:373282539638 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472958623_368494982166
2024-12-22 04:39:01,540 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:01,540 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:01,549 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/external-resource-gpu/flink-external-resource-gpu-1.11-byted-SNAPSHOT.jar fileId:373282540950 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472959930_368494983474
2024-12-22 04:39:01,654 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false

2024-12-22 04:39:01,654 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:01,665 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/external-resource-gpu/gpu-discovery-common.sh fileId:373282541861 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472960843_368494984387
2024-12-22 04:39:01,815 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:01,815 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:01,824 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/external-resource-gpu/nvidia-gpu-discovery.sh fileId:373282543185 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472962155_368494985701
2024-12-22 04:39:06,632 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:06,632 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:06,986 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/hive-udf/flink-hive-udf.jar fileId:373282575851 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369472995063_368495018615
2024-12-22 04:39:10,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:39:11,234 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false

2024-12-22 04:39:11,235 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:11,595 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-datadog/flink-metrics-datadog-1.11-byted-SNAPSHOT.jar fileId:373282618138 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473037554_368495061111
2024-12-22 04:39:12,442 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:12,442 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:12,578 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-graphite/flink-metrics-graphite-1.11-byted-SNAPSHOT.jar fileId:373282628244 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473047461_368495071019
2024-12-22 04:39:12,938 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:12,939 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:13,025 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-influx/flink-metrics-influxdb-1.11-byted-SNAPSHOT.jar fileId:373282632672 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473051973_368495075531
2024-12-22 04:39:13,227 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:13,228 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled

2024-12-22 04:39:13,250 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-jmx/flink-metrics-jmx-1.11-byted-SNAPSHOT.jar fileId:373282634932 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473054302_368495077860
2024-12-22 04:39:13,426 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:13,427 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:13,435 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-prometheus/flink-metrics-prometheus-1.11-byted-SNAPSHOT.jar fileId:373282636637 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473055958_368495079516
2024-12-22 04:39:15,174 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:15,174 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:15,181 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-slf4j/flink-metrics-slf4j-1.11-byted-SNAPSHOT.jar fileId:373282645469 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473064779_368495088341
2024-12-22 04:39:15,369 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:15,369 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:15,377 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/metrics-statsd/flink-metrics-statsd-1.11-byted-SNAPSHOT.jar fileId:373282646590 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473065894_368495089456

2024-12-22 04:39:15,806 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:15,806 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:15,856 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/plugins/s3-fs-presto/flink-s3-fs-presto-1.11-byted-SNAPSHOT.jar fileId:373282648631 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473067865_368495091429
2024-12-22 04:39:17,335 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:17,335 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:17,344 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/dts-lark-source.jar fileId:373282656908 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473075674_368495099241
2024-12-22 04:39:17,511 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:17,511 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:17,518 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/dts-hive1-2-sink.jar fileId:373282657894 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473076726_368495100295
2024-12-22 04:39:18,698 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false

2024-12-22 04:39:18,698 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:18,705 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/dts-hive1-2-core.jar fileId:373282665003 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473083576_368495107145
2024-12-22 04:39:20,711 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Tracking url is empty, waiting 10 seconds
2024-12-22 04:39:22,795 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:22,795 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:22,818 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/dts-lark-core.jar fileId:373282696673 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473114776_368495138350
2024-12-22 04:39:23,525 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:23,525 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:23,544 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/dts-hadoop2-6-core.jar fileId:373282703429 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473121373_368495144948
2024-12-22 04:39:23,875 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false

2024-12-22 04:39:23,875 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:23,902 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/dts-batch-core.jar fileId:373282706925 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473124941_368495148516
2024-12-22 04:39:24,670 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:24,670 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:24,679 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/flink-dist_2.11-1.11-byted-SNAPSHOT.jar fileId:373282714888 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473132835_368495156413
2024-12-22 04:39:26,900 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:26,900 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:39:26,907 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/application_1734453112995_47034447265407534612088374.tmp fileId:373282724267 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473141959_368495165540
2024-12-22 04:39:27,088 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:39:27,088 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled

2024-12-22 04:39:27,095 INFO  org.apache.hadoop.hdfs.DFSClient                             - check parameters before write block, StorageType:0 src:/flink_maliva/model01/1.11/.flink/application_1734453112995_4703444/application_1734453112995_4703444-flink-conf.yaml1110828191741699820.tmp fileId:373282724851 ResidentTimeSet:true residentTimeSec:0 netPriority:0 ioPriority:null blockCopy:BP-1014801734-10.110.141.231-1545987732966:blk_369473142565_368495166147
2024-12-22 04:39:27,296 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - classPathBuilder: dts-batch-core.jar:dts-hadoop2-6-core.jar:dts-hive1-2-core.jar:dts-hive1-2-sink.jar:dts-lark-core.jar:dts-lark-source.jar::lib/flink-cloud-shuffle-1.11-byted-SNAPSHOT.jar:lib/flink-connector-preview-1.11-byted-SNAPSHOT.jar:lib/flink-csv-1.11-byted-SNAPSHOT.jar:lib/flink-json-1.11-byted-SNAPSHOT.jar:lib/flink-metrics-databus-1.11-byted-SNAPSHOT.jar:lib/flink-metrics-dropwizard-1.11-byted-SNAPSHOT.jar:lib/flink-metrics-opentsdb-1.11-byted-SNAPSHOT.jar:lib/flink-shaded-hadoop-2-uber-2.6.0-cdh5.4.4-bd346-11.0-byted-20240620.133602-2.jar:lib/flink-shaded-zookeeper-3.5.9.jar:lib/flink-state-processor-api_2.11-1.11-byted-SNAPSHOT.jar:lib/flink-table-blink_2.11-1.11-byted-SNAPSHOT.jar:lib/flink-table_2.11-1.11-byted-SNAPSHOT.jar:lib/log4j-1.2-api-2.17.1.jar:lib/log4j-api-2.17.1.jar:lib/log4j-core-2.17.1.jar:lib/log4j-slf4j-impl-2.17.1.jar:flink-dist_2.11-1.11-byted-SNAPSHOT.jar:job.graph:flink-conf.yaml:
2024-12-22 04:39:27,673 INFO  org.apache.flink.yarn.Utils                                  - Deactivate docker image, run on physical machines.
2024-12-22 04:39:27,717 INFO  org.apache.hadoop.conf.Configuration                         - found resource resource-types.xml at file:/opt/tiger/yarn_deploy/hadoop-2.6.0-cdh5.4.4/conf/resource-types.xml
2024-12-22 04:39:27,733 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = yarn.io/gpu, units = , type = COUNTABLE
2024-12-22 04:39:27,733 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = yarn.io/tpu-v3-base, units = , type = COUNTABLE
2024-12-22 04:39:27,733 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = yarn.io/tpu-v3-pod, units = , type = COUNTABLE
2024-12-22 04:39:27,733 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = yarn.io/port, units = , type = COUNTABLE
2024-12-22 04:39:27,734 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = memory-mb, units = Mi, type = COUNTABLE
2024-12-22 04:39:27,734 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = vcores, units = , type = COUNTABLE

2024-12-22 04:39:27,734 INFO  org.apache.hadoop.yarn.util.resource.ResourceUtils           - Adding resource type - name = vcores-milli, units = m, type = COUNTABLE
2024-12-22 04:39:27,745 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - Use ResLake init yarn client.
2024-12-22 04:39:27,746 INFO  org.apache.hadoop.yarn.conf.YarnConfiguration                - Change cluster to mouse (by queue name: yarn.queue.name=root.mouse_ecom_dw)
2024-12-22 04:39:27,746 WARN  org.apache.hadoop.yarn.conf.YarnConfiguration                - User configuration for cluster name is conflict. (mouse in yarn.queue.name != model01 in yarn.cluster.name). Using default cluster name in queue.
2024-12-22 04:39:27,762 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - Would write application metadata to /tmp/appid
2024-12-22 04:39:27,763 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - Submitting application master application_1734453112995_4703444
2024-12-22 04:39:27,773 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dccd:cde2:1002:acbb:ca51:d404:3090:8032 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:39:27,809 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - Wrote application metadata file /tmp/appid
2024-12-22 04:39:28,012 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - Submitted application application_1734453112995_4703444
2024-12-22 04:39:28,012 INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl        - Application Tracking URL: https://model01-megarm.tiktok-row.net/proxy/application_1734453112995_4703444/

2024-12-22 04:39:28,012 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - Waiting for the cluster to be allocated
2024-12-22 04:39:28,015 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - Deploying cluster, current state ACCEPTED
2024-12-22 04:39:30,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842370002, timeStamp 1734842370
2024-12-22 04:39:30,711 INFO  com.bytedance.bitsail.component.progress.bytedance.context.BytedanceYarnJobDeployContext - Getting tracking url from conf path success: https://model01-megarm.tiktok-row.net/proxy/application_1734453112995_4703444/
2024-12-22 04:39:30,746 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:39:37,497 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dc61:c:423:0:0:0:153:65212 from donglihua. Request send 150. receive 150. Calls remain 0.
2024-12-22 04:39:40,717 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:39:50,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:39:53,967 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - YARN application has been deployed successfully.
2024-12-22 04:39:53,968 INFO  org.apache.flink.yarn.YarnClusterDescriptor                  - Found Web Interface [fdbd:dc61:10:772::220]:35005 of application 'application_1734453112995_4703444'.

2024-12-22 04:39:53,973 INFO  org.apache.flink.client.deployment.executors.AbstractJobClusterExecutor - Job has been submitted with JobID 256215842b1a6fd6ead19ba389539de0
Job has been submitted with JobID 256215842b1a6fd6ead19ba389539de0
2024-12-22 04:39:54,137 INFO  org.apache.flink.client.ClientUtils                          - Begin to report client's heartbeat for the job 256215842b1a6fd6ead19ba389539de0.
2024-12-22 04:40:00,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842400002, timeStamp 1734842400
2024-12-22 04:40:00,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:40:03,966 INFO  org.apache.hadoop.ipc.Client                                 - IPC Client exit. Name: IPC Client (234988139) connection to /fdbd:dccd:cde2:1002:acbb:ca51:d404:3090:8032 from donglihua. Request send 28. receive 28. Calls remain 0.
2024-12-22 04:40:10,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:40:20,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:40:30,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842430002, timeStamp 1734842430
2024-12-22 04:40:30,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds

2024-12-22 04:40:40,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:40:50,715 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:41:00,002 INFO  org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.PeriodicMetricPublisher - Schedule MetricReader[class org.apache.flink.shaded.byted.com.bytedance.metrics2.core.instrument.reader.PipeMetricReader] invoke now 1734842460002, timeStamp 1734842460
2024-12-22 04:41:00,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
Program execution finished
Job with JobID 256215842b1a6fd6ead19ba389539de0 has finished.
Job Runtime: 74120 ms
Accumulator Results: 
- input_1491090087_1734842251156_COUNT_TASK_RETRY_COUNT (java.lang.Long): 0
- input_1491090087_1734842251156_COUNT_SUCCESS_RECORDS_BYTES (java.lang.Long): 6163874

- output_1491090087_1734842251156_LIST_DIRTY (java.util.ArrayList) [0 elements]
- input_1491090087_1734842251156_COUNT_SUCCESS_RECORDS_COUNT (java.lang.Long): 60175
- hive.partition.key.date=20241221 (java.lang.Long): 60175
- input_1491090087_1734842251156_LIST_DIRTY (java.util.ArrayList) [0 elements]
- output_1491090087_1734842251156_COUNT_TASK_RETRY_COUNT (java.lang.Long): 0
- output_1491090087_1734842251156_COUNT_FAILED_RECORDS_COUNT (java.lang.Long): 0
- output_1491090087_1734842251156_COUNT_SUCCESS_RECORDS_COUNT (java.lang.Long): 60175
- input_1491090087_1734842251156_COUNT_FAILED_RECORDS_COUNT (java.lang.Long): 0
- output_1491090087_1734842251156_COUNT_SUCCESS_RECORDS_BYTES (java.lang.Long): 6163874



2024-12-22 04:41:06,268 INFO  org.apache.flink.api.java.ExecutionEnvironment               - Shut down the cluster.
2024-12-22 04:41:06,349 INFO  com.bytedance.bitsail.flink.core.execution.FlinkExecutionEnviron - Flink job finished, execution result: 

***********************************************
              Job Execute Result
***********************************************
Job Start Time            : 2024-12-22 04:38:00
Job End Time              : 2024-12-22 04:41:06
Job Input Success Records :               60175

Job Input Failed Records  :                   0
Job Output Success Records:               60175
Job Output Failed Records :                   0
***********************************************
.
2024-12-22 04:41:06,350 INFO  com.bytedance.dts.core.legacy.connector.InputFormatPlugin    - Checking dirty records during input...
2024-12-22 04:41:06,351 INFO  com.bytedance.bitsail.base.messenger.checker.DirtyRecordChecker - Group READER found 60175 success records.
2024-12-22 04:41:06,351 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.
2024-12-22 04:41:06,351 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:41:06,351 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.

2024-12-22 04:41:06,352 INFO  com.bytedance.dts.core.legacy.connector.OutputFormatPlugin   - Checking dirty records during output...
2024-12-22 04:41:06,352 INFO  com.bytedance.bitsail.base.messenger.checker.DirtyRecordChecker - Group WRITER found 60175 success records.
2024-12-22 04:41:06,352 INFO  org.apache.flink.runtime.fs.hdfs.HadoopFsFactory             - Initialize hadoop filesystem(uri=hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002/tmp)
2024-12-22 04:41:06,380 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:41:06,380 INFO  org.apache.flink.runtime.fs.hdfs.HadoopFsFactory             - Initialize filesystem hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002/tmp
2024-12-22 04:41:06,381 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider -  Log in ConfiguredFailoverProxyProvider Initialized proxy lists: 
 host: harunava
 consul enabled: false
 Consul service name:
 Consul Dcs: 

 ProxyThresholdNums:5
 AlertNumsDecreaseRate:0.8
 refreshIntervalMS:300000
2024-12-22 04:41:06,386 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider - conf addressesOfNns: 
[/fdbd:dc61:10:201:0:0:0:19:65212, /fdbd:dc61:10:201:0:0:0:39:65212, /fdbd:dc61:10:201:0:0:0:21:65212, /fdbd:dc61:10:219:0:0:0:166:65212, /fdbd:dc61:10:219:0:0:0:164:65212, /fdbd:dc61:9:179:0:0:0:170:65212, /fdbd:dc61:9:53:0:0:0:45:65212, /fdbd:dc61:9:459:0:0:0:146:65212, /fdbd:dc61:9:453:0:0:0:29:65212, /fdbd:dc61:9:467:0:0:0:159:65212, /fdbd:dc61:6:131:0:0:0:12:65212, /fdbd:dc61:9:563:0:0:0:165:65212, /fdbd:dc61:6:135:0:0:0:14:65212, /fdbd:dc61:6:135:0:0:0:12:65212, /fdbd:dc61:6:135:0:0:0:44:65212, /fdbd:dc61:6:135:0:0:0:19:65212, /fdbd:dc61:6:135:0:0:0:48:65212, /fdbd:dc61:6:135:0:0:0:47:65212, /fdbd:dc61:6:136:0:0:0:90:65212, /fdbd:dc61:6:136:0:0:0:87:65212, /fdbd:dc61:6:136:0:0:0:91:65212, /fdbd:dc61:6:136:0:0:0:93:65212, /fdbd:dc61:6:136:0:0:0:92:65212, /fdbd:dc61:6:137:0:0:0:133:65212, /fdbd:dc61:6:137:0:0:0:132:65212, /fdbd:dc61:6:137:0:0:0:135:65212, /fdbd:dc61:6:137:0:0:0:134:65212, /fdbd:dc61:6:138:0:0:0:196:65212, /fdbd:dc61:6:138:0:0:0:194:65212, /fdbd:dc61:6:138:0:0:0:197:65212, /fdbd:dc61:6:138:0:0:0:201:65212, /fdbd:dc61:6:138:0:0:0:199:65212, /fdbd:dc61:6:139:0:0:0:13:65212, /fdbd:dc61:6:139:0:0:0:12:65212, /fdbd:dc61:6:139:0:0:0:18:65212, /fdbd:dc61:6:139:0:0:0:14:65212, /fdbd:dc61:6:140:0:0:0:69:65212, /fdbd:dc61:6:140:0:0:0:67:65212, /fdbd:dc61:6:140:0:0:0:73:65212, /fdbd:dc61:6:140:0:0:0:70:65212, /fdbd:dc61:c:235:0:0:0:139:65212, /fdbd:dc61:a:185:0:0:0:47:65212, /fdbd:dc61:c:235:0:0:0:142:65212, /fdbd:dc61:a:237:0:0:0:31:65212, /fdbd:dc61:a:237:0:0:0:30:65212, /fdbd:dc61:7:266:0:0:0:92:65212, /fdbd:dc61:7:266:0:0:0:85:65212, /fdbd:dc61:4:35:0:0:0:14:65212, /fdbd:dc61:7:272:0:0:0:225:65212, /fdbd:dc61:7:272:0:0:0:208:65212, /fdbd:dc61:4:37:0:0:0:168:65212, /fdbd:dc61:7:292:0:0:0:209:65212, /fdbd:dc61:4:37:0:0:0:153:65212, /fdbd:dc61:7:278:0:0:0:66:65212, /fdbd:dc61:7:292:0:0:0:207:65212, /fdbd:dc61:4:40:0:0:0:88:65212, /fdbd:dc61:7:290:0:0:0:105:65212, /fdbd:dc61:4:39:0:0:0:12:65212, /fdbd:dc61:7:290:0:0:0:85:65212, /fdbd:dc61:101:168:0:0:0:92:65212, /fdbd:dc61:7:294:0:0:0:84:65212, /fdbd:dc61:4:41:0:0:0:139:65212, /fdbd:dc61:7:294:0:0:0:82:65212, /fdbd:dc61:101:214:0:0:0:221:65212, /fdbd:dc61:7:292:0:0:0:224:65212, /fdbd:dc61:101:214:0:0:0:218:65212, /fdbd:dc61:7:292:0:0:0:213:65212, /fdbd:dc61:101:214:0:0:0:203:65212, /fdbd:dc61:101:214:0:0:0:198:65212, /fdbd:dc61:101:168:0:0:0:76:65212, /fdbd:dc61:101:214:0:0:0:207:65212, /fdbd:dc61:7:282:0:0:0:91:65212, /fdbd:dc61:101:214:0:0:0:215:65212, /fdbd:dc61:7:280:0:0:0:237:65212, /fdbd:dc61:101:168:0:0:0:83:65212, /fdbd:dc61:7:280:0:0:0:224:65212, /fdbd:dc61:101:168:0:0:0:75:65212, /fdbd:dc61:101:109:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:217:65212, /fdbd:dc61:101:129:0:0:0:168:65212, /fdbd:dc61:7:288:0:0:0:213:65212, /fdbd:dc61:5:22:0:0:0:196:65212, /fdbd:dc61:7:288:0:0:0:212:65212, /fdbd:dc61:101:134:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:208:65212, /fdbd:dc61:7:290:0:0:0:75:65212, /fdbd:dc61:7:290:0:0:0:73:65212, /fdbd:dc61:7:288:0:0:0:232:65212, /fdbd:dc61:101:216:0:0:0:92:65212, /fdbd:dc61:4:33:0:0:0:130:65212, /fdbd:dc61:4:34:0:0:0:210:65212, /fdbd:dc61:4:36:0:0:0:100:65212, /fdbd:dc61:6:406:0:0:0:223:65212, /fdbd:dc61:6:300:0:0:0:19:65212, /fdbd:dc61:6:303:0:0:0:219:65212, /fdbd:dc61:6:303:0:0:0:199:65212, /fdbd:dc61:6:300:0:0:0:21:65212, /fdbd:dc61:b:487:0:0:0:134:65212, /fdbd:dc61:6:408:0:0:0:95:65212, /fdbd:dc61:a:14:0:0:0:107:65212, /fdbd:dc61:c:423:0:0:0:153:65212, /fdbd:dc61:a:15:0:0:0:132:65212, /fdbd:dc61:a:318:0:0:0:91:65212, /fdbd:dc61:a:16:0:0:0:197:65212, /fdbd:dc61:10:195:0:0:0:143:65212, /fdbd:dc61:a:468:0:0:0:235:65212, /fdbd:dc61:10:197:0:0:0:14:65212, /fdbd:dc61:10:195:0:0:0:155:65212, /fdbd:dc61:10:199:0:0:0:138:65212, /fdbd:dc61:10:197:0:0:0:53:65212, /fdbd:dc61:10:201:0:0:0:17:65212, /fdbd:dc61:10:199:0:0:0:156:65212]
conf addressesOfNns nums:112
2024-12-22 04:41:06,387 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using switch reads; ; threshold=30ms; window length=16; change block reader ratio=0.5; read in same dc weight=4; increase read size min speed up=5; default block reader minimum read bytes=1MB; maximum read bytes=100MB; minimum read bytes=2MB
2024-12-22 04:41:06,388 INFO  org.apache.hadoop.fs.FileSystem                              - Initialize DistributedFileSystem. Yarn Deploy version: @@version@@
2024-12-22 04:41:06,395 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dc61:4:40:0:0:0:88:65212 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:41:06,396 INFO  org.apache.hadoop.security.token.btdsec.SecTokenSelector     - Looking for a token with service fdbd:dc61:4:40:0:0:0:88:65212

2024-12-22 04:41:06,412 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Check hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002/tmp finished. result: false. Taken: 0.019 sec.
2024-12-22 04:41:06,412 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - hive partition will merge data
2024-12-22 04:41:06,417 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:41:06,417 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:41:06,417 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:06,420 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:06,420 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:06,420 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:06,426 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:06,426 INFO  hive.metastore                                               - Parsed nodes size: 613

2024-12-22 04:41:06,428 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:10:706::103]:11350
2024-12-22 04:41:06,428 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:10:706::103]:11350
2024-12-22 04:41:09,315 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:41:09,315 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:09,317 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:09,317 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:09,317 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:09,321 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:09,321 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:41:09,322 INFO  hive.metastore                                               - Connected to metastore.

2024-12-22 04:41:09,323 INFO  org.apache.hadoop.fs.FileSystem                              - Init FileSystem. Hadoop client version: @@version@@
2024-12-22 04:41:09,323 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider -  Log in ConfiguredFailoverProxyProvider Initialized proxy lists: 
 host: harunavaali
 consul enabled: false
 Consul service name:
 Consul Dcs: 
 ProxyThresholdNums:5
 AlertNumsDecreaseRate:0.8
 refreshIntervalMS:300000
2024-12-22 04:41:09,327 INFO  org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider - conf addressesOfNns: 

[/fdbd:dc61:10:201:0:0:0:19:65212, /fdbd:dc61:10:201:0:0:0:39:65212, /fdbd:dc61:10:201:0:0:0:21:65212, /fdbd:dc61:10:219:0:0:0:166:65212, /fdbd:dc61:10:219:0:0:0:164:65212, /fdbd:dc61:9:179:0:0:0:170:65212, /fdbd:dc61:9:53:0:0:0:45:65212, /fdbd:dc61:9:459:0:0:0:146:65212, /fdbd:dc61:9:453:0:0:0:29:65212, /fdbd:dc61:9:467:0:0:0:159:65212, /fdbd:dc61:6:131:0:0:0:12:65212, /fdbd:dc61:9:563:0:0:0:165:65212, /fdbd:dc61:6:135:0:0:0:14:65212, /fdbd:dc61:6:135:0:0:0:12:65212, /fdbd:dc61:6:135:0:0:0:44:65212, /fdbd:dc61:6:135:0:0:0:19:65212, /fdbd:dc61:6:135:0:0:0:48:65212, /fdbd:dc61:6:135:0:0:0:47:65212, /fdbd:dc61:6:136:0:0:0:90:65212, /fdbd:dc61:6:136:0:0:0:87:65212, /fdbd:dc61:6:136:0:0:0:91:65212, /fdbd:dc61:6:136:0:0:0:93:65212, /fdbd:dc61:6:136:0:0:0:92:65212, /fdbd:dc61:6:137:0:0:0:133:65212, /fdbd:dc61:6:137:0:0:0:132:65212, /fdbd:dc61:6:137:0:0:0:135:65212, /fdbd:dc61:6:137:0:0:0:134:65212, /fdbd:dc61:6:138:0:0:0:196:65212, /fdbd:dc61:6:138:0:0:0:194:65212, /fdbd:dc61:6:138:0:0:0:197:65212, /fdbd:dc61:6:138:0:0:0:201:65212, /fdbd:dc61:6:138:0:0:0:199:65212, /fdbd:dc61:6:139:0:0:0:13:65212, /fdbd:dc61:6:139:0:0:0:12:65212, /fdbd:dc61:6:139:0:0:0:18:65212, /fdbd:dc61:6:139:0:0:0:14:65212, /fdbd:dc61:6:140:0:0:0:69:65212, /fdbd:dc61:6:140:0:0:0:67:65212, /fdbd:dc61:6:140:0:0:0:73:65212, /fdbd:dc61:6:140:0:0:0:70:65212, /fdbd:dc61:c:235:0:0:0:139:65212, /fdbd:dc61:a:185:0:0:0:47:65212, /fdbd:dc61:c:235:0:0:0:142:65212, /fdbd:dc61:a:237:0:0:0:31:65212, /fdbd:dc61:a:237:0:0:0:30:65212, /fdbd:dc61:7:266:0:0:0:92:65212, /fdbd:dc61:7:266:0:0:0:85:65212, /fdbd:dc61:4:35:0:0:0:14:65212, /fdbd:dc61:7:272:0:0:0:225:65212, /fdbd:dc61:7:272:0:0:0:208:65212, /fdbd:dc61:4:37:0:0:0:168:65212, /fdbd:dc61:7:292:0:0:0:209:65212, /fdbd:dc61:4:37:0:0:0:153:65212, /fdbd:dc61:7:278:0:0:0:66:65212, /fdbd:dc61:7:292:0:0:0:207:65212, /fdbd:dc61:4:40:0:0:0:88:65212, /fdbd:dc61:7:290:0:0:0:105:65212, /fdbd:dc61:4:39:0:0:0:12:65212, /fdbd:dc61:7:290:0:0:0:85:65212, /fdbd:dc61:101:168:0:0:0:92:65212, /fdbd:dc61:7:294:0:0:0:84:65212, /fdbd:dc61:4:41:0:0:0:139:65212, /fdbd:dc61:7:294:0:0:0:82:65212, /fdbd:dc61:101:214:0:0:0:221:65212, /fdbd:dc61:7:292:0:0:0:224:65212, /fdbd:dc61:101:214:0:0:0:218:65212, /fdbd:dc61:7:292:0:0:0:213:65212, /fdbd:dc61:101:214:0:0:0:203:65212, /fdbd:dc61:101:214:0:0:0:198:65212, /fdbd:dc61:101:168:0:0:0:76:65212, /fdbd:dc61:101:214:0:0:0:207:65212, /fdbd:dc61:7:282:0:0:0:91:65212, /fdbd:dc61:101:214:0:0:0:215:65212, /fdbd:dc61:7:280:0:0:0:237:65212, /fdbd:dc61:101:168:0:0:0:83:65212, /fdbd:dc61:7:280:0:0:0:224:65212, /fdbd:dc61:101:168:0:0:0:75:65212, /fdbd:dc61:101:109:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:217:65212, /fdbd:dc61:101:129:0:0:0:168:65212, /fdbd:dc61:7:288:0:0:0:213:65212, /fdbd:dc61:5:22:0:0:0:196:65212, /fdbd:dc61:7:288:0:0:0:212:65212, /fdbd:dc61:101:134:0:0:0:211:65212, /fdbd:dc61:7:288:0:0:0:208:65212, /fdbd:dc61:7:290:0:0:0:75:65212, /fdbd:dc61:7:290:0:0:0:73:65212, /fdbd:dc61:7:288:0:0:0:232:65212, /fdbd:dc61:101:216:0:0:0:92:65212, /fdbd:dc61:4:33:0:0:0:130:65212, /fdbd:dc61:4:34:0:0:0:210:65212, /fdbd:dc61:4:36:0:0:0:100:65212, /fdbd:dc61:6:406:0:0:0:223:65212, /fdbd:dc61:6:300:0:0:0:19:65212, /fdbd:dc61:6:303:0:0:0:219:65212, /fdbd:dc61:6:303:0:0:0:199:65212, /fdbd:dc61:6:300:0:0:0:21:65212, /fdbd:dc61:b:487:0:0:0:134:65212, /fdbd:dc61:6:408:0:0:0:95:65212, /fdbd:dc61:a:14:0:0:0:107:65212, /fdbd:dc61:c:423:0:0:0:153:65212, /fdbd:dc61:a:15:0:0:0:132:65212, /fdbd:dc61:a:318:0:0:0:91:65212, /fdbd:dc61:a:16:0:0:0:197:65212, /fdbd:dc61:10:195:0:0:0:143:65212, /fdbd:dc61:a:468:0:0:0:235:65212, /fdbd:dc61:10:197:0:0:0:14:65212, /fdbd:dc61:10:195:0:0:0:155:65212, /fdbd:dc61:10:199:0:0:0:138:65212, /fdbd:dc61:10:197:0:0:0:53:65212, /fdbd:dc61:10:201:0:0:0:17:65212, /fdbd:dc61:10:199:0:0:0:156:65212]
conf addressesOfNns nums:112
2024-12-22 04:41:09,328 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using switch reads; ; threshold=30ms; window length=16; change block reader ratio=0.5; read in same dc weight=4; increase read size min speed up=5; default block reader minimum read bytes=1MB; maximum read bytes=100MB; minimum read bytes=2MB
2024-12-22 04:41:09,329 INFO  org.apache.hadoop.fs.FileSystem                              - Initialize DistributedFileSystem. Yarn Deploy version: @@version@@
2024-12-22 04:41:09,330 INFO  org.apache.hadoop.ipc.Client                                 - Init IPC Client (234988139) connection to /fdbd:dc61:6:140:0:0:0:69:65212 from donglihua, trySasl=true, tryCustomSasl=false
2024-12-22 04:41:09,331 INFO  org.apache.hadoop.security.token.btdsec.SecTokenSelector     - Looking for a token with service fdbd:dc61:6:140:0:0:0:69:65212
2024-12-22 04:41:09,904 INFO  org.apache.hadoop.hive.ql.session.SessionState               - Created HDFS directory: /tmp/hive_i18n/SCRATCH_DATE/hive-root/donglihua/833f51e5-9a6d-410e-b429-80965bbd5cff
2024-12-22 04:41:10,205 INFO  org.apache.hadoop.hive.ql.session.SessionState               - Created HDFS directory: /tmp/hive_i18n/SCRATCH_DATE/hive-root/donglihua/833f51e5-9a6d-410e-b429-80965bbd5cff/_tmp_space.db
2024-12-22 04:41:10,359 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:41:10,359 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice

2024-12-22 04:41:10,359 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:10,361 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:10,361 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:10,361 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:10,364 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:10,364 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:41:10,366 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:10:800::228]:11770
2024-12-22 04:41:10,367 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:10:800::228]:11770
2024-12-22 04:41:10,715 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:41:11,251 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice

2024-12-22 04:41:11,251 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:11,253 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:11,253 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:11,253 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:11,257 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:11,258 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:41:11,259 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:41:11,259 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842471_Jiz4B22fhD
2024-12-22 04:41:11,300 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842471_Jiz4B22fhD, Latency=41ms
2024-12-22 04:41:11,301 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842471_XaeSNqafkC

2024-12-22 04:41:11,375 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842471_XaeSNqafkC, Latency=74ms
2024-12-22 04:41:11,377 INFO  com.bytedance.bitsail.shaded.hive.client.HiveMetaClientUtil  - fetch database: ecom_dev table: app_lgt_test_lineitem location: hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221, Taken: 4 sec.
2024-12-22 04:41:11,377 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842471_N8Q5TOoML6
2024-12-22 04:41:11,378 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - partition date=20241221 has nums 60175
2024-12-22 04:41:11,378 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - task has static origin partition date=20241221
2024-12-22 04:41:11,378 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - add static partition date=20241221 to result
2024-12-22 04:41:11,379 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 246 users=2 expired=false closed=false
2024-12-22 04:41:11,379 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842471_hUhU1QkgWF
2024-12-22 04:41:11,379 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:41:11,379 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2

2024-12-22 04:41:11,380 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:41:11,380 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:41:12,423 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372
2024-12-22 04:41:12,423 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:41:12,424 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:12,425 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:12,425 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:12,425 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:12,430 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:12,430 INFO  hive.metastore                                               - Parsed nodes size: 613

2024-12-22 04:41:12,431 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:a:329::37]:11002
2024-12-22 04:41:12,432 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:a:329::37]:11002
2024-12-22 04:41:13,328 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:41:13,328 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:13,329 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:13,329 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:13,329 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:13,333 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:13,333 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:41:13,335 INFO  hive.metastore                                               - Connected to metastore.

2024-12-22 04:41:13,339 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_partition, CS_TRACE_ID=CS_1734842473_jrdLPHJ97n
2024-12-22 04:41:13,603 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842473_jrdLPHJ97n, Latency=264ms
2024-12-22 04:41:13,603 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842473_T7CnjClwJb
2024-12-22 04:41:13,603 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - drop partition path: hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221
2024-12-22 04:41:13,605 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Check hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221 finished. result: false. Taken: 0.001 sec.
2024-12-22 04:41:13,605 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - Starting commit tmp dir hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 to hive output path hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem.
2024-12-22 04:41:13,607 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Check hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 finished. result: true. Taken: 0.001 sec.
2024-12-22 04:41:13,608 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Check hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 finished. result: true. Taken: 0.001 sec.
2024-12-22 04:41:13,610 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] getFileStatus hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 finished. Taken: 0.001 sec.
2024-12-22 04:41:13,612 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] listStatus hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 finished. Taken: 0.001 sec.

2024-12-22 04:41:13,614 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Check hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221 finished. result: false. Taken: 0.001 sec.
2024-12-22 04:41:13,619 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] mkdir hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221 finished. result: true Taken: 0.005 sec.
2024-12-22 04:41:13,620 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] listStatus hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002/date=20241221 finished. Taken: 0.001 sec.
2024-12-22 04:41:13,620 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - rename file: hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002/date=20241221/part-0-1491090087-1734842428101 to dirPath: hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221/part-0-1491090087-1734842428101
2024-12-22 04:41:13,622 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component log loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:41:13,622 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component nop loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:41:13,622 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component bytedance-metric-reporter loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:41:13,622 INFO  com.bytedance.bitsail.base.component.DefaultComponentBuilderLoader - Component influxdb loaded in clazz interface com.bytedance.bitsail.base.metrics.reporter.MetricReporterBuilder.
2024-12-22 04:41:13,622 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Metric prefix is dp.dts.
2024-12-22 04:41:13,623 INFO  com.bytedance.metrics.udpclient.MetricsClient                - metrics sdk use localhost inet socket to emit metrics

2024-12-22 04:41:13,623 INFO  com.bytedance.bitsail.base.version.ReleaseTagHolder          - Release tag is 
2024-12-22 04:41:13,623 INFO  com.bytedance.bitsail.base.metrics.manager.BitSailMetricManager - MetricManager responsible for group 'batch' of task UNKNOWN with identifier '0' is initialized by c.b.d.b.m.MetricsFactory#getBatchJobMetrics:84
2024-12-22 04:41:13,624 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric batch.releaseTagHeartbeat{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:13,624 INFO  com.bytedance.dts.base.metrics.MetricsFactory                - Job 105520594 add job metric group
2024-12-22 04:41:13,624 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric batch.hdfs.rename.timeuse.throughput{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:13,625 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric batch.hdfs.rename.timeuse.latency{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:13,635 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Rename hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002/date=20241221/part-0-1491090087-1734842428101 to hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221/part-0-1491090087-1734842428101 finished, result: true. Taken: 0.008 sec.
2024-12-22 04:41:13,635 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric batch.hdfs.rename_success.count{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:13,636 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric batch.hive.output.client.hdfs.rename.time{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:13,636 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric batch.hive.output.client.hdfs.rename.time{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.

2024-12-22 04:41:13,636 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - commit tmp dir to hive dir, Taken: 0 sec
2024-12-22 04:41:13,636 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - add partition path: /default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221 with nums: 60175
2024-12-22 04:41:13,637 INFO  com.bytedance.bitsail.shaded.hive.client.HiveMetaClientUtil  - Start to add partition date=20241221 to ecom_dev.app_lgt_test_lineitem on location /default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221
2024-12-22 04:41:13,637 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Unexpected increment of user count beyond one: 2 HCatClient: thread: 246 users=2 expired=false closed=false
2024-12-22 04:41:13,638 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842473_nq8oKbdOHF
2024-12-22 04:41:13,638 INFO  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - check hive client status: Cannot write to null outputStream
2024-12-22 04:41:13,638 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Evicted client has non-zero user count: 2
2024-12-22 04:41:13,638 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=2 expired=true
2024-12-22 04:41:13,638 WARN  com.bytedance.bitsail.shaded.hive.cache.DtsHiveClientCache   - Non-zero user count preventing client tear down: users=1 expired=true
2024-12-22 04:41:14,658 INFO  hive.metastore                                               - /opt/tiger/hive_deploy version:1.0.0.2372

2024-12-22 04:41:14,658 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice
2024-12-22 04:41:14,659 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:14,660 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:14,660 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:14,660 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:14,663 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:14,663 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:41:14,665 INFO  hive.metastore                                               - Trying to connect to metastore with URI thrift://[fdbd:dc61:7:433::46]:11196
2024-12-22 04:41:14,665 INFO  hive.metastore                                               - Succeeded to connect to the MetaStore Server : thrift://[fdbd:dc61:7:433::46]:11196
2024-12-22 04:41:15,715 INFO  hive.metastore                                               - Try to connect to metastore through hive.metastore.consul.name.first: data.olap.catalogservice

2024-12-22 04:41:15,715 INFO  hive.metastore                                               - Try to parse metatsore uri from consul: data.olap.catalogservice
2024-12-22 04:41:15,717 INFO  hive.metastore                                               - client IPv6 addr: fdbd:dc61:5:300::88
2024-12-22 04:41:15,717 INFO  hive.metastore                                               - client IPv4 addr: 10.190.216.88
2024-12-22 04:41:15,717 INFO  hive.metastore                                               - hive.client.enable.prefer_ipv6: true
2024-12-22 04:41:15,720 INFO  hive.metastore                                               - Parsed nodes, ipv4:0, ipv6:613
2024-12-22 04:41:15,720 INFO  hive.metastore                                               - Parsed nodes size: 613
2024-12-22 04:41:15,722 INFO  hive.metastore                                               - Connected to metastore.
2024-12-22 04:41:15,722 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=get_table, CS_TRACE_ID=CS_1734842475_g6ley9toVV
2024-12-22 04:41:15,864 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842475_g6ley9toVV, Latency=142ms
2024-12-22 04:41:15,869 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=add_partition_with_environment_context, CS_TRACE_ID=CS_1734842475_qkW2LZFXFI

2024-12-22 04:41:17,697 INFO  HiveTTraceManager                                            - Ends tracing: CS_TRACE_ID=CS_1734842475_qkW2LZFXFI, Latency=1828ms
2024-12-22 04:41:17,697 INFO  com.bytedance.bitsail.shaded.hive.client.HiveMetaClientUtil  - Add partitions date=20241221 to ecom_dev.Table(tableName:app_lgt_test_lineitem, dbName:ecom_dev, owner:donglihua, createTime:1734842125, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:orderkey, type:bigint, comment:orderkey), FieldSchema(name:partkey, type:bigint, comment:partkey), FieldSchema(name:suppkey, type:bigint, comment:suppkey), FieldSchema(name:linenumber, type:bigint, comment:linenumber), FieldSchema(name:quantity, type:bigint, comment:quantity), FieldSchema(name:extendedprice, type:decimal(38,6), comment:extendedprice), FieldSchema(name:discount, type:decimal(38,6), comment:discount), FieldSchema(name:tax, type:decimal(38,6), comment:tax), FieldSchema(name:returnflag, type:string, comment:returnflag), FieldSchema(name:linestatus, type:string, comment:linestatus), FieldSchema(name:shipdate, type:string, comment:shipdate), FieldSchema(name:commitdate, type:string, comment:commitdate), FieldSchema(name:receiptdate, type:string, comment:receiptdate), FieldSchema(name:shipinstruct, type:string, comment:shipinstruct), FieldSchema(name:shipmode, type:string, comment:shipmode), FieldSchema(name:comment, type:string, comment:comment)], location:/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{}), storedAsSubDirectories:false), partitionKeys:[FieldSchema(name:date, type:string, comment:date)], parameters:{is_core=false, creation_platform=coral, spark.sql.sources.schema.partCol.0=date, transient_lastDdlTime=1734842126, parquet.compression=zstd, ttl=7, spark.sql.create.version=3.2.1-bd1-SNAPSHOT, last_update_time=1734842126, is_starred=false, spark.sql.sources.schema.numPartCols=1, spark.sql.sources.schema.part.0={"type":"struct","fields":[{"name":"orderkey","type":"long","nullable":true,"metadata":{"comment":"orderkey"}},{"name":"partkey","type":"long","nullable":true,"metadata":{"comment":"partkey"}},{"name":"suppkey","type":"long","nullable":true,"metadata":{"comment":"suppkey"}},{"name":"linenumber","type":"long","nullable":true,"metadata":{"comment":"linenumber"}},{"name":"quantity","type":"long","nullable":true,"metadata":{"comment":"quantity"}},{"name":"extendedprice","type":"decimal(38,6)","nullable":true,"metadata":{"comment":"extendedprice"}},{"name":"discount","type":"decimal(38,6)","nullable":true,"metadata":{"comment":"discount"}},{"name":"tax","type":"decimal(38,6)","nullable":true,"metadata":{"comment":"tax"}},{"name":"returnflag","type":"string","nullable":true,"metadata":{"comment":"returnflag"}},{"name":"linestatus","type":"string","nullable":true,"metadata":{"comment":"linestatus"}},{"name":"shipdate","type":"string","nullable":true,"metadata":{"comment":"shipdate"}},{"name":"commitdate","type":"string","nullable":true,"metadata":{"comment":"commitdate"}},{"name":"receiptdate","type":"string","nullable":true,"metadata":{"comment":"receiptdate"}},{"name":"shipinstruct","type":"string","nullable":true,"metadata":{"comment":"shipinstruct"}},{"name":"shipmode","type":"string","nullable":true,"metadata":{"comment":"shipmode"}},{"name":"comment","type":"string","nullable":true,"metadata":{"comment":"comment"}},{"name":"date","type":"string","nullable":true,"metadata":{"comment":"date"}}]}, ttl_extension={"type":"pname"}, spark.sql.sources.schema.numParts=1, status=3}, viewOriginalText:null, viewExpandedText:null, tableType:MANAGED_TABLE, globalType:LOCAL) Finished. Taken: 4 sec
2024-12-22 04:41:17,698 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842477_3rNRVWsDLc
2024-12-22 04:41:17,698 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - task has static origin partition date=20241221
2024-12-22 04:41:17,698 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - Touch successFlagPath /default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221/_SUCCESS
2024-12-22 04:41:17,704 INFO  org.apache.hadoop.hdfs.pipeline.FastFailoverStrategy         - FastFailOverStrategy Configuration, slowAckThresholdMs:5000, ackSamplingWindow:16, ackSamplingSLowThreshold:10, maxFailOverTimes:5, blockBytesThreshold:52428800, use throughput instead of slow ack number false
2024-12-22 04:41:17,704 INFO  org.apache.hadoop.hdfs.DFSClient                             - Using FastFailOverStrategy in DFSOutStream, FastFailOverStrategy is enabled
2024-12-22 04:41:17,705 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Touch hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/date=20241221/_SUCCESS finished. Taken: 0.006 sec.
2024-12-22 04:41:17,709 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - Finished commit tmp dir to output dir, Taken: 4 sec
2024-12-22 04:41:17,710 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric batch.hdfs.rename.timeuse.throughput{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.

2024-12-22 04:41:17,710 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric batch.releaseTagHeartbeat{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:17,710 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric batch.hdfs.rename.timeuse.latency{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8}.
2024-12-22 04:41:17,710 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Close metric client!
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.successInputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.successInputRecordBytes{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.failedInputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.successOutputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.successOutputRecordBytes{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.failedOutputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,711 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.taskRetryCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.

2024-12-22 04:41:17,716 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds
2024-12-22 04:41:17,717 INFO  com.bytedance.bitsail.base.execution.ExecutionEnviron        - DTS job start terminal.
2024-12-22 04:41:17,717 INFO  com.bytedance.bitsail.flink.core.execution.FlinkExecutionEnviron - Flink job start terminal.
2024-12-22 04:41:17,717 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.
2024-12-22 04:41:17,717 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:41:17,717 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Login security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.
2024-12-22 04:41:17,719 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Check hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 finished. result: true. Taken: 0.002 sec.
2024-12-22 04:41:17,719 INFO  com.bytedance.dts.batch.hive.parquet.HiveParquetOutputFormat - Target temp output path hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 exists. The program will delete it.
2024-12-22 04:41:17,732 INFO  com.bytedance.dts.common.util.HdfsUtils                      - [HDFS Operation] Delete hdfs://harunava/default/home/byte_cmp_ecom_stats_va/warehouse/ecom_dev.db/app_lgt_test_lineitem/dts-tmp-105520594-1491090087-1734842268002 finished. result: true. Taken: 0.013 sec.
2024-12-22 04:41:17,732 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule.

2024-12-22 04:41:17,732 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.HadoopSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:41:17,732 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule.
2024-12-22 04:41:17,732 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.JaasSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:41:17,732 INFO  com.bytedance.dts.core.security.kerberos.HadoopKerberosSecured - Logout security module com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule.
2024-12-22 04:41:17,732 INFO  com.bytedance.bitsail.component.format.security.kerberos.module.ZookeeperSecurityModule - activated is false and is login is false, return directly
2024-12-22 04:41:17,733 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.success{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,733 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Add metric client.duration{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,733 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.taskRetryCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,733 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.successInputRecordBytes{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.start{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.

2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.successInputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.success{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.successOutputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.duration{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.successOutputRecordBytes{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.releaseTagHeartbeat{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.failedInputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - remove metric client.failedOutputRecordCount{git_commit=89729d607672e6e7a5681e48b74122244c2f4865,priority_id=0,project_id=521,source=LarkSheet,job=105520594,version=0.2.0-SNAPSHOT,release_tag=,worker_id=8,target=Hive}.
2024-12-22 04:41:17,734 INFO  com.bytedance.bitsail.component.metric.bytedance.BytedanceMetricReporter - Close metric client!
2024-12-22 04:41:17,737 INFO  com.bytedance.bitsail.component.progress.bytedance.base.AbstractFlinkJobProgress - Job info is empty, waiting 10 seconds

2024-12-22 04:41:17,738 INFO  com.bytedance.bitsail.flink.core.execution.FlinkExecutionEnviron - Flink job terminal finished.
2024-12-22 04:41:17,738 INFO  com.bytedance.bitsail.base.execution.ExecutionEnviron        - DTS job terminal finished.
2024-12-22 04:41:17,739 INFO  org.apache.flink.metrics.opentsdb.OpentsdbReporter           - OpentsdbReporter closed.
2024-12-22 04:41:17,741 INFO  com.bytedance.bitsail.base.execution.ExecutionEnviron        - DTS job already in terminal.
2024-12-22 04:41:17,743 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842477_BpgsqzwCyd
2024-12-22 04:41:17,743 INFO  HiveTTraceManager                                            - Starts tracing: CS_METHOD=shutdown, CS_TRACE_ID=CS_1734842477_GsH9zrfrUt

2024-12-22T04:41:18.436 INFO  =================================================================
2024-12-22T04:41:18.436 INFO  instance[1491090087] execute finished, result=0
2024-12-22T04:41:18.436 INFO  instance[1491090087] post-execute finished
2024-12-22T04:41:18.436 INFO  execute status: SUCCEEDED
2024-12-22T04:41:18.465 INFO  The manta trick request is MantaTriggerRequest(projectId=521, taskId=105520594, taskType=126, instanceId=1491090087, taskTimeStr=2024-12-21 00:00:00.000, retryNum=0, isDebug=true, isMultiEnv=true, triggerType=debug)
2024-12-22T04:41:18.709 INFO  The instance:1491090087 find 0 manta rules.
2024-12-22T04:41:18.709 INFO  instance: 1491090087 will exit in code: 0
2024-12-22T04:41:18.715 INFO  Shutdown status:SUCCEEDED
2024-12-22T04:41:18.727 INFO  Start handling instance action: FINISH_SUCCEEDED for instance with id 1491090087
2024-12-22T04:41:18.727 INFO  Start to change instance status from RUNNING to SUCCEEDED_DOWNSTREAM.
